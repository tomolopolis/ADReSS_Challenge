{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import regex as re\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, mean_squared_error\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFClassifier, XGBRegressor, XGBRFRegressor\n",
    "from xgboost import plot_importance\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interspeech 2020 Challenge\n",
    "Deadline: May 8th submission of predictions and paper.\n",
    "\n",
    "Main Webpage: http://www.interspeech2020.org/index.php?m=content&c=index&a=lists&catid=66\n",
    "\n",
    "Challenge Webpage: http://www.homepages.ed.ac.uk/sluzfil/ADReSS/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Plan\n",
    "Only using the transcripts:\n",
    "- [x] Simple clean and join all sentences, classifiy using DistillBERT, (BERT), (RoBERTa)   ## Done\n",
    "\n",
    "## Further Feature Engineering:\n",
    "### Time dimension\n",
    "- Embed time total time taken - parse time blocks, take first and last\n",
    "- Embed total time taken per sentence\n",
    "- Time before starting speech\n",
    "- Time in between each sentence\n",
    "- Average / min / max / median time of sentence\n",
    "- use of special characters\n",
    "- number of sentences spoken\n",
    "\n",
    "### Linguistic Features\n",
    "- Embed special character tokens in speech, pauses etc. (not sure if this needed, tokenzier / and\n",
    "- classify on a sentence level??\n",
    "- Also use the Interviewer INV, questions / speech / time...\n",
    "- Use POS Tags: as OHE vector\n",
    "\n",
    "## Demographics\n",
    "- Gender\n",
    "- Age\n",
    "\n",
    "## Fine-tuning BERT(-esque) models on spontaneous speech datasets\n",
    "- fine-tune and re-classify using other spontaneous speech datasets: \n",
    "\n",
    "### Further work on\n",
    "- Analysis of what roBERTa has actually learned in the attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ad_dir = '../train/transcription/cd/*'\n",
    "controls_dir = '../train/transcription/cc/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_name):\n",
    "    par = {}\n",
    "    par['id'] = file_name.split('/')[-1].split('.cha')[0]\n",
    "    f = iter(open(file_name))\n",
    "    l = next(f)\n",
    "    speech = []\n",
    "    try:\n",
    "        curr_speech = ''\n",
    "        while (True):\n",
    "            if l.startswith('@ID'):\n",
    "                participant = [i.strip() for i in l.split('|')]\n",
    "                if participant[2] == 'PAR':\n",
    "                    par['mmse'] = '' if len(participant[8]) == 0 else float(participant[8])\n",
    "                    par['sex'] = participant[4][0]\n",
    "                    par['age'] = int(participant[3].replace(';', ''))\n",
    "            if l.startswith('*PAR:') or l.startswith('*INV'):\n",
    "                curr_speech = l\n",
    "            elif len(curr_speech) != 0 and not(l.startswith('%') or l.startswith('*')):\n",
    "                curr_speech += l\n",
    "            elif len(curr_speech) > 0:\n",
    "                speech.append(curr_speech)\n",
    "                curr_speech = ''\n",
    "            l = next(f)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    clean_par_speech = []\n",
    "    clean_all_speech = []\n",
    "    speech_time_segments = []\n",
    "    is_par = False\n",
    "    for s in speech:\n",
    "        def _clean(s):\n",
    "            speech_time_segments.append([*map(int, re.search('\\x15(\\d*_\\d*)\\x15', s).groups()[0].split('_'))])\n",
    "            s = re.sub('\\x15\\d*_\\d*\\x15', '', s) # remove time block \n",
    "            s = re.sub('\\[.*\\]', '', s) # remove other speech artifacts [.*]\n",
    "            s = s.strip()\n",
    "            s = re.sub('\\t|\\n|<|>', '', s) # remove tab, new lines, inferred speech??, ampersand, &\n",
    "            return s\n",
    "        \n",
    "        if s.startswith('*PAR:'):\n",
    "            is_par = True\n",
    "        elif s.startswith('*INV:'):\n",
    "            is_par = False\n",
    "            s = re.sub('\\*INV:\\t', '', s) # remove prefix\n",
    "        if is_par:\n",
    "            s = re.sub('\\*PAR:\\t', '', s) # remove prefix    \n",
    "            clean_par_speech.append(_clean(s))\n",
    "        clean_all_speech.append(_clean(s))\n",
    "    \n",
    "    par['speech'] = speech\n",
    "    par['clean_speech'] = clean_all_speech\n",
    "    par['clean_par_speech'] = clean_par_speech\n",
    "    par['joined_all_speech'] = ' '.join(clean_all_speech)\n",
    "    par['joined_all_par_speech'] = ' '.join(clean_par_speech)\n",
    "    \n",
    "    # sentence times\n",
    "    par['per_sent_times'] = [speech_time_segments[i][1] - speech_time_segments[i][0] for i in range(len(speech_time_segments))]\n",
    "    par['total_time'] =  speech_time_segments[-1][1] - speech_time_segments[0][0]\n",
    "    par['time_before_par_speech'] = speech_time_segments[0][0]\n",
    "    par['time_between_sents'] = [0 if i == 0 else max(0, speech_time_segments[i][0] - speech_time_segments[i-1][1]) \n",
    "                                 for i in range(len(speech_time_segments))]\n",
    "    return par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_data():\n",
    "    return _parse_data('../data/train')\n",
    "    \n",
    "def parse_test_data():\n",
    "    return _parse_data('../data/test')\n",
    "\n",
    "def parse_pre_train_data():\n",
    "    return _parse_data('/data/train')\n",
    "\n",
    "def _parse_data(data_dir):\n",
    "    prob_ad_dir = f'{data_dir}/transcription/cd/*'\n",
    "    controls_dir = f'{data_dir}/transcription/cc/*'\n",
    "    \n",
    "    prob_ad = [extract_data(fn) for fn in glob(prob_ad_dir)]\n",
    "    controls = [extract_data(fn) for fn in glob(controls_dir)]\n",
    "    controls_df = pd.DataFrame(controls)\n",
    "    prob_ad_df = pd.DataFrame(prob_ad)\n",
    "    controls_df['ad'] = 0\n",
    "    prob_ad_df['ad'] = 1\n",
    "    df = pd.concat([controls_df, prob_ad_df]).sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = parse_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_speech = train_df.apply(lambda r: pd.DataFrame({'id': r.id, 'speech_sent': r.clean_par_speech, 'ad': r.ad, 'mmse': r.mmse}), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode out each segment into AD / control segments\n",
    "# Do not shuffle, as parent level segments have already been shuffled?\n",
    "train_df_segments = pd.concat(segmented_speech).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-line TF-IDF -> GBDT / SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cv10_avg(score, model, features, labels):\n",
    "    return round(cross_val_score(model, features, labels, cv=10, scoring=score).sum() / 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def baseline_models(text: pd.Series, labels: list, mmse: list, xgb=True):\n",
    "    ## AD Classification Pred\n",
    "    # sklearn pipeline\n",
    "    param_space = {\n",
    "        'vec__max_features': [100, 500, 1000, 2000, 10000],\n",
    "        'vec__stop_words': ['english', None],\n",
    "        'vec__analyzer': ['word', 'char'],\n",
    "        'vec__sublinear_tf': [True, False]       \n",
    "    }    \n",
    "    if xgb:\n",
    "        param_space['clf__n_estimators'] = [100, 200, 500]  \n",
    "        param_space['clf__max_depth'] = [3, 5, 10]\n",
    "    else:\n",
    "        param_space['clf__C'] = [0.1, 0.5, 1.]              \n",
    "        param_space['clf__kernel'] = ['rbf', 'sigmoid']    \n",
    "\n",
    "    clf_pipe = Pipeline([\n",
    "        ('vec', TfidfVectorizer()),\n",
    "        ('clf', XGBClassifier()) if xgb else ('clf', SVC())\n",
    "    ])\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(text, labels, random_state=random_state, test_size=0.2)\n",
    "    search = GridSearchCV(clf_pipe, param_space, cv=5, n_jobs=6)\n",
    "    search.fit(train_features, train_labels)\n",
    "\n",
    "    clf_pipe.set_params(**search.best_params_)\n",
    "    print(search.best_params_)\n",
    "    clf_pipe.fit(train_features, train_labels)\n",
    "    preds = clf_pipe.predict(test_features)\n",
    "    print('prec, rec, f1 test', precision_recall_fscore_support(test_labels, preds))\n",
    "    print(f'accu:{cv10_avg(\"accuracy\", clf_pipe, text, labels)}')\n",
    "    print(f'prec:{cv10_avg(\"precision\", clf_pipe, text, labels)}')\n",
    "    print(f'rec:{cv10_avg(\"recall\", clf_pipe, text, labels)}')\n",
    "    print(f'f1:{cv10_avg(\"f1\", clf_pipe, text, labels)}')\n",
    "\n",
    "    ## MMSE Regression Pred\n",
    "    reg_features, reg_scores = text.drop([i for i, s in enumerate(mmse) if s == '']).reset_index(drop=True), [s for s in mmse if s != '']\n",
    "    train_features, test_features, train_scores, test_scores = train_test_split(reg_features, reg_scores, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    # sklearn pipeline\n",
    "    param_space = {\n",
    "        'vec__max_features': [100, 500, 1000, 2000, 10000],\n",
    "        'vec__stop_words': ['english', None],\n",
    "        'vec__analyzer': ['word', 'char'],\n",
    "        'vec__sublinear_tf': [True, False]\n",
    "    }    \n",
    "    if xgb:\n",
    "        param_space['clf__n_estimators'] = [100, 200, 500]  \n",
    "        param_space['clf__max_depth'] = [3, 5, 10]  \n",
    "    else:\n",
    "        param_space['clf__C'] = [0.1, 0.5, 1.]              \n",
    "        param_space['clf__kernel'] = ['rbf', 'sigmoid']   \n",
    "\n",
    "    rgs_pipe = Pipeline([\n",
    "        ('vec', TfidfVectorizer()),\n",
    "        ('clf', XGBRegressor()) if xgb else ('clf', SVR())\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(rgs_pipe, param_space, cv=5, n_jobs=6)\n",
    "    search.fit(train_features, train_scores)\n",
    "\n",
    "    rgs_pipe.set_params(**search.best_params_)\n",
    "    print(search.best_params_)\n",
    "    rgs_pipe.fit(train_features, train_scores)\n",
    "    preds = rgs_pipe.predict(test_features)\n",
    "    print('rmse test:', sqrt(mean_squared_error(test_scores, preds)))\n",
    "    print('rmse cv:', cross_val_score(rgs_pipe, reg_features, reg_scores, cv=10, scoring='neg_root_mean_squared_error').sum() / 10)\n",
    "\n",
    "    return clf_pipe, rgs_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.0, 'clf__kernel': 'rbf', 'vec__analyzer': 'word', 'vec__max_features': 1000, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "prec, rec, f1 test (array([0.84615385, 1.        ]), array([1.        , 0.81818182]), array([0.91666667, 0.9       ]), array([11, 11]))\n",
      "accu:0.86\n",
      "prec:0.91\n",
      "rec:0.84\n",
      "f1:0.85\n",
      "{'clf__C': 1.0, 'clf__kernel': 'sigmoid', 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': 'english', 'vec__sublinear_tf': True}\n",
      "rmse test: 6.715101139865216\n",
      "rmse cv: -5.828961412118949\n"
     ]
    }
   ],
   "source": [
    "# SVM - par speech only\n",
    "clf_svm, rgs_svm = baseline_models(train_df.joined_all_par_speech, train_df.ad,  train_df.mmse, xgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.0, 'clf__kernel': 'rbf', 'vec__analyzer': 'word', 'vec__max_features': 500, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "prec, rec, f1 test (array([0.83333333, 0.9       ]), array([0.90909091, 0.81818182]), array([0.86956522, 0.85714286]), array([11, 11]))\n",
      "accu:0.88\n",
      "prec:0.92\n",
      "rec:0.87\n",
      "f1:0.87\n",
      "{'clf__C': 1.0, 'clf__kernel': 'sigmoid', 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "rmse test: 6.674597551339369\n",
      "rmse cv: -5.734230349579695\n"
     ]
    }
   ],
   "source": [
    "# SVM - par + inv speech\n",
    "clf_svm, rgs_svm = baseline_models(train_df.joined_all_speech, train_df.ad, train_df.mmse, xgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 5, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 1000, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "prec, rec, f1 test (array([0.75, 0.8 ]), array([0.81818182, 0.72727273]), array([0.7826087 , 0.76190476]), array([11, 11]))\n",
      "accu:0.84\n",
      "prec:0.86\n",
      "rec:0.84\n",
      "f1:0.84\n",
      "{'clf__max_depth': 3, 'clf__n_estimators': 200, 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': 'english', 'vec__sublinear_tf': False}\n",
      "rmse test: 6.537925257229833\n",
      "rmse cv: -5.561295795181303\n"
     ]
    }
   ],
   "source": [
    "# XGBoost - par speech only\n",
    "clf_xgb_par, rgs_xgb_par = baseline_models(train_df.joined_all_par_speech, train_df.ad, train_df.mmse, xgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 3, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': 'english', 'vec__sublinear_tf': False}\n",
      "prec, rec, f1 test (array([0.75, 0.8 ]), array([0.81818182, 0.72727273]), array([0.7826087 , 0.76190476]), array([11, 11]))\n",
      "accu:0.79\n",
      "prec:0.8\n",
      "rec:0.82\n",
      "f1:0.79\n",
      "{'clf__max_depth': 3, 'clf__n_estimators': 200, 'vec__analyzer': 'char', 'vec__max_features': 100, 'vec__stop_words': 'english', 'vec__sublinear_tf': False}\n",
      "rmse test: 6.370420306954228\n",
      "rmse cv: -5.603149994529027\n"
     ]
    }
   ],
   "source": [
    "# XGBoost - par + inv speech\n",
    "clf_xgb_all, rgs_xgb_all = baseline_models(train_df.joined_all_par_speech, train_df.ad, train_df.mmse, xgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.0, 'clf__kernel': 'rbf', 'vec__analyzer': 'word', 'vec__max_features': 1000, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "prec, rec, f1 test (array([0.75384615, 0.73493976]), array([0.69014085, 0.79220779]), array([0.72058824, 0.7625    ]), array([142, 154]))\n",
      "accu:0.72\n",
      "prec:0.72\n",
      "rec:0.73\n",
      "f1:0.72\n",
      "{'clf__C': 1.0, 'clf__kernel': 'sigmoid', 'vec__analyzer': 'word', 'vec__max_features': 500, 'vec__stop_words': None, 'vec__sublinear_tf': False}\n",
      "rmse test: 7.318767768806731\n",
      "rmse cv: -7.0807403858703735\n"
     ]
    }
   ],
   "source": [
    "# SVM - segmented\n",
    "clf_svm, rgs_svm = baseline_models(train_df_segments.speech_sent, train_df_segments.ad, train_df_segments.mmse, xgb=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 3, 'clf__n_estimators': 200, 'vec__analyzer': 'word', 'vec__max_features': 500, 'vec__stop_words': None, 'vec__sublinear_tf': False}\n",
      "prec, rec, f1 test (array([0.65753425, 0.69333333]), array([0.67605634, 0.67532468]), array([0.66666667, 0.68421053]), array([142, 154]))\n",
      "accu:0.68\n",
      "prec:0.68\n",
      "rec:0.71\n",
      "f1:0.69\n",
      "{'clf__max_depth': 3, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 1000, 'vec__stop_words': None, 'vec__sublinear_tf': False}\n",
      "rmse test: 6.964259148338462\n",
      "rmse cv: -6.996732925985971\n"
     ]
    }
   ],
   "source": [
    "# XGBoost - segmented\n",
    "clf_svm, rgs_svm = baseline_models(train_df_segments.speech_sent, train_df_segments.ad, train_df_segments.mmse, xgb=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def feat_impor(pipe):\n",
    "    feat_impor = [(pipe.steps[0][1].get_feature_names()[i], pipe.steps[1][1].feature_importances_[i]) for i in np.argsort(pipe.steps[1][1].feature_importances_)[::-1][0:20]]\n",
    "    labs = [i[0] for i in feat_impor]\n",
    "    scores = [i[1] for i in feat_impor]\n",
    "    return labs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plt_feats(clf_labels, clf_impor, rgs_labels, rgs_impor):\n",
    "    fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax1.barh(range(len(clf_impor)), clf_impor, label='AD Classification')\n",
    "    ax1.set_yticks(range(len(clf_labels)))\n",
    "    ax1.set_yticklabels(clf_labels)\n",
    "    ax1.set_ylabel('TF-IDF Feature')\n",
    "    ax1.set_xlabel('Feature Importance')\n",
    "\n",
    "    ax2.barh(range(len(rgs_labels)), rgs_impor, label='MMSE Regression')\n",
    "    ax2.set_yticks(range(len(rgs_labels)))\n",
    "    ax2.set_yticklabels(rgs_labels)\n",
    "    ax2.set_ylabel('TF-IDF Feature')\n",
    "    ax2.set_xlabel('Feature Importance')\n",
    "\n",
    "    # plt.legend([bar1, bar2], [bar1.get_label(), bar2.get_label()], fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./feat_impor_xgboost.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clf_labels, clf_impor = \n",
    "# rgs_labels, rgs_impor =\n",
    "plt_feats(*feat_impor(clf_xgb_par), * feat_impor(rgs_xgb_par))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (type) model Experimentaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding function\n",
    "def bert_embed(text: pd.Series, tokenizer, model):\n",
    "    tokenized = text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512)))\n",
    "\n",
    "    # pad so can be treated as one batch\n",
    "    max_len = max([len(i) for i in tokenized.values])\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "    # attention mask - zero out attention scores where there is no input to be processed (i.e. is padding)\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    input_ids = torch.tensor(padded)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # check if multiple GPUs are available\n",
    "    multi_gpu = torch.cuda.device_count() > 1\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    last_hidden_states = last_hidden_states[0]\n",
    "    if device.type == 'cuda':\n",
    "        last_hidden_states = last_hidden_states.cpu()\n",
    "    features = last_hidden_states[:,0,:].numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear classifier fit/transform\n",
    "def fit_transform(features, labels: list, mmse: list):\n",
    "    def cv10_avg_nn(score):\n",
    "        return cv10_avg(score, lr_clf, features, labels)\n",
    "\n",
    "    # AD classification task\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=random_state)\n",
    "    parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "    grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
    "    grid_search.fit(train_features, train_labels)\n",
    "    print('best parameters:', grid_search.best_params_)\n",
    "    print('best scores: ', grid_search.best_score_)\n",
    "    lr_clf = LogisticRegression(**grid_search.best_params_)\n",
    "    lr_clf.fit(train_features, train_labels)\n",
    "    preds = lr_clf.predict(test_features)\n",
    "    print('prec, rec, f1 test', precision_recall_fscore_support(test_labels, preds))\n",
    "    print(f'accu:{cv10_avg_nn(\"accuracy\")} prec:{cv10_avg_nn(\"precision\")}, rec:{cv10_avg_nn(\"recall\")}, f1:{cv10_avg_nn(\"f1\")}')\n",
    "          \n",
    "    # MMSE regression task\n",
    "    # remove missing row\n",
    "    reg_features, reg_scores = pd.DataFrame(features).drop([i for i, s in enumerate(mmse) if s == '']).to_numpy(), [s for s in mmse if s != '']\n",
    "    train_features, test_features, train_scores, test_scores = train_test_split(reg_features, reg_scores, random_state=random_state)\n",
    "    parameters = {'alpha': np.linspace(0.001, 100, 20)}\n",
    "    grid_search = GridSearchCV(Ridge(), parameters)\n",
    "    grid_search.fit(train_features, train_scores)\n",
    "    print('best parameters:', grid_search.best_params_)\n",
    "    print('best scores: ', grid_search.best_score_)\n",
    "    reg_model = Ridge(**grid_search.best_params_)\n",
    "    reg_model.fit(train_features, train_scores)\n",
    "    preds = reg_model.predict(test_features)\n",
    "    print('rmse test:', sqrt(mean_squared_error(test_scores, preds)))\n",
    "    print('rmse cv:', cross_val_score(reg_model, reg_features, reg_scores, cv=10, scoring='neg_root_mean_squared_error').sum() / 10)\n",
    "    return lr_clf, reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Large\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-large-uncased')\n",
    "\n",
    "# roBERTa base\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
    "\n",
    "# roBERTa large\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transformer_model_tokenizer(model_class, tokenizer_class, pretrained_weights):\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_class, tokenizer_class, pretrained_weights, text):\n",
    "    tokenizer, model = load_transformer_model_tokenizer(model_class, tokenizer_class, pretrained_weights)\n",
    "    features = bert_embed(text, tokenizer, model)\n",
    "    clf_model, reg_model = fit_transform(features, train_df.ad, train_df.mmse)\n",
    "    return tokenizer, model, features, clf_model, reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8279411764705882\n",
      "prec, rec, f1 test (array([0.81818182, 0.8125    ]), array([0.75      , 0.86666667]), array([0.7826087 , 0.83870968]), array([12, 15]))\n",
      "accu:0.87 prec:0.9, rec:0.87, f1:0.87\n",
      "best parameters: {'alpha': 5.264105263157894}\n",
      "best scores:  0.48426174008121115\n",
      "rmse test: 5.156365006865598\n",
      "rmse cv: -4.496598650519269\n"
     ]
    }
   ],
   "source": [
    "# Distil BERT - par speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_par_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8294117647058823\n",
      "prec, rec, f1 test (array([1.        , 0.88235294]), array([0.83333333, 1.        ]), array([0.90909091, 0.9375    ]), array([12, 15]))\n",
      "accu:0.84 prec:0.86, rec:0.85, f1:0.82\n",
      "best parameters: {'alpha': 0.001}\n",
      "best scores:  0.39129614202351315\n",
      "rmse test: 5.99993232969807\n",
      "rmse cv: -5.125356983051849\n"
     ]
    }
   ],
   "source": [
    "# Distil roBERTa\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'distilroberta-base')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_par_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8294117647058823\n",
      "prec, rec, f1 test (array([1.        , 0.88235294]), array([0.83333333, 1.        ]), array([0.90909091, 0.9375    ]), array([12, 15]))\n",
      "accu:0.84 prec:0.86, rec:0.85, f1:0.82\n",
      "best parameters: {'alpha': 0.001}\n",
      "best scores:  0.39129614202351315\n",
      "rmse test: 5.99993232969807\n",
      "rmse cv: -5.125356983051849\n"
     ]
    }
   ],
   "source": [
    "# BERT Base\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_par_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8147058823529412\n",
      "prec, rec, f1 test (array([0.90909091, 0.875     ]), array([0.83333333, 0.93333333]), array([0.86956522, 0.90322581]), array([12, 15]))\n",
      "accu:0.87 prec:0.89, rec:0.89, f1:0.88\n",
      "best parameters: {'alpha': 5.264105263157894}\n",
      "best scores:  0.4361080418716384\n",
      "rmse test: 5.891775312607294\n",
      "rmse cv: -4.8560381474639875\n"
     ]
    }
   ],
   "source": [
    "# Distil BERT - par + inv speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8147058823529412\n",
      "prec, rec, f1 test (array([0.90909091, 0.875     ]), array([0.83333333, 0.93333333]), array([0.86956522, 0.90322581]), array([12, 15]))\n",
      "accu:0.87 prec:0.89, rec:0.89, f1:0.88\n",
      "best parameters: {'alpha': 5.264105263157894}\n",
      "best scores:  0.4361080418716384\n",
      "rmse test: 5.891775312607294\n",
      "rmse cv: -4.8560381474639875\n"
     ]
    }
   ],
   "source": [
    "# BERT Base -  par + inv speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time features\n",
    "# - Embed time total time taken \n",
    "# - parse time blocks, take first and last\n",
    "# - Embed total time taken per sentence\n",
    "# - Time before starting speech\n",
    "# - Time in between each sentence\n",
    "# - Average / min / max / median time of sentence\n",
    "time_dims = train_df.loc[:, ['total_time', 'time_before_par_speech', 'time_between_sents', 'per_sent_times']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dims['avg_betweeen_sents'] = time_dims.time_between_sents.apply(lambda t: round(sum(t) / len(t)))\n",
    "time_dims['max'] = time_dims.time_between_sents.apply(max)\n",
    "time_dims['min'] = time_dims.time_between_sents.apply(min)\n",
    "time_dims_eng = time_dims.drop('time_between_sents', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_before_par_speech</th>\n",
       "      <th>time_between_sents</th>\n",
       "      <th>per_sent_times</th>\n",
       "      <th>avg_betweeen_sents</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28249</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[7580, 7580, 2750, 2750, 1670, 1670, 1277, 127...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39304</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3700, 2167, 2633, 2633, 3795, 3795, 2785, 278...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108061</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2475, 3757, 7084, 7084, 7681, 7681, 3657, 365...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70330</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[997, 831, 1014, 1014, 3958, 3958, 3102, 3102,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84322</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1829, 1064, 3271, 3806, 770, 770, 14216, 1421...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>190561</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2913, 11657, 11657, 14986, 14986, 12979, 1297...</td>\n",
       "      <td>49</td>\n",
       "      <td>732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>56600</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1829, 2013, 2013, 558, 558, 1919, 1919, 12302...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>88250</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1573, 5913, 5913, 2614, 2614, 4376, 4376, 652...</td>\n",
       "      <td>439</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>81475</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1853, 6097, 6097, 1512, 1512, 7161, 7161, 610...</td>\n",
       "      <td>34</td>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>44683</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1813, 620, 620, 1757, 1757, 6500, 6500, 1764,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_time  time_before_par_speech  \\\n",
       "0         28249                       0   \n",
       "1         39304                       0   \n",
       "2        108061                       0   \n",
       "3         70330                       0   \n",
       "4         84322                       0   \n",
       "..          ...                     ...   \n",
       "103      190561                       0   \n",
       "104       56600                       0   \n",
       "105       88250                       0   \n",
       "106       81475                       0   \n",
       "107       44683                       0   \n",
       "\n",
       "                                    time_between_sents  \\\n",
       "0        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    [0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "..                                                 ...   \n",
       "103  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "104  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "105  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "106  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "107  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        per_sent_times  avg_betweeen_sents  \\\n",
       "0    [7580, 7580, 2750, 2750, 1670, 1670, 1277, 127...                   0   \n",
       "1    [3700, 2167, 2633, 2633, 3795, 3795, 2785, 278...                   0   \n",
       "2    [2475, 3757, 7084, 7084, 7681, 7681, 3657, 365...                   0   \n",
       "3    [997, 831, 1014, 1014, 3958, 3958, 3102, 3102,...                   0   \n",
       "4    [1829, 1064, 3271, 3806, 770, 770, 14216, 1421...                   3   \n",
       "..                                                 ...                 ...   \n",
       "103  [2913, 11657, 11657, 14986, 14986, 12979, 1297...                  49   \n",
       "104  [1829, 2013, 2013, 558, 558, 1919, 1919, 12302...                   0   \n",
       "105  [1573, 5913, 5913, 2614, 2614, 4376, 4376, 652...                 439   \n",
       "106  [1853, 6097, 6097, 1512, 1512, 7161, 7161, 610...                  34   \n",
       "107  [1813, 620, 620, 1757, 1757, 6500, 6500, 1764,...                   0   \n",
       "\n",
       "       max  min  \n",
       "0        0    0  \n",
       "1        0    0  \n",
       "2        0    0  \n",
       "3        0    0  \n",
       "4      100    0  \n",
       "..     ...  ...  \n",
       "103    732    0  \n",
       "104      0    0  \n",
       "105  10520    0  \n",
       "106    897    0  \n",
       "107      0    0  \n",
       "\n",
       "[108 rows x 7 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.clean_par_speech.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = StandardScaler().fit_transform(time_dims_eng.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForADClassification(torch.nn.Module):\n",
    "    def __init__(self, bertModel, time_dims,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bertModel = bertModel\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        \n",
    "        # separate Linear for OHE of time\n",
    "        bert_hidden_dim = self.bertModel\n",
    "    \n",
    "        self.classifier = nn.Linear()\n",
    "    \n",
    "    def forward(input_ids, attention_mask):\n",
    "        last_hidden_states = self.bertModel(input_ids, attention_mask=attention_mask)\n",
    "        features = last_hidden_states[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all features\n",
    "features = np.hstack([bert_features, time_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:distil_bert]",
   "language": "python",
   "name": "conda-env-distil_bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
