{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import regex as re\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, mean_squared_error\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interspeech 2020 Challenge\n",
    "Deadline: May 8th submission of predictions and paper.\n",
    "\n",
    "Main Webpage: http://www.interspeech2020.org/index.php?m=content&c=index&a=lists&catid=66\n",
    "\n",
    "Challenge Webpage: http://www.homepages.ed.ac.uk/sluzfil/ADReSS/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Plan\n",
    "Only using the transcripts:\n",
    "- [x] Simple clean and join all sentences, classifiy using DistillBERT, (BERT), (RoBERTa)   ## Done\n",
    "\n",
    "## Further Feature Engineering:\n",
    "### Time dimension\n",
    "- Embed time total time taken - parse time blocks, take first and last\n",
    "- Embed total time taken per sentence\n",
    "- Time before starting speech\n",
    "- Time in between each sentence\n",
    "- Average / min / max / median time of sentence\n",
    "- use of special characters\n",
    "- number of sentences spoken\n",
    "\n",
    "### Linguistic Features\n",
    "- Embed special character tokens in speech, pauses etc. (not sure if this needed, tokenzier / and\n",
    "- classify on a sentence level??\n",
    "- Also use the Interviewer INV, questions / speech / time...\n",
    "- Use POS Tags: as OHE vector\n",
    "\n",
    "## Demographics\n",
    "- Gender\n",
    "- Age\n",
    "\n",
    "## Fine-tuning BERT(-esque) models on spontaneous speech datasets\n",
    "- fine-tune and re-classify using other spontaneous speech datasets: \n",
    "\n",
    "### Further work on\n",
    "- Analysis of what roBERTa has actually learned in the attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ad_dir = '../train/transcription/cd/*'\n",
    "controls_dir = '../train/transcription/cc/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_data(file_name):\n",
    "    par = {}\n",
    "    par['id'] = file_name.split('/')[-1].split('.cha')[0]\n",
    "    f = iter(open(file_name))\n",
    "    l = next(f)\n",
    "    speech = []\n",
    "    try:\n",
    "        curr_speech = ''\n",
    "        while (True):\n",
    "            if l.startswith('@ID'):\n",
    "                participant = [i.strip() for i in l.split('|')]\n",
    "                if participant[2] == 'PAR':\n",
    "                    par['mmse'] = '' if len(participant[8]) == 0 else float(participant[8])\n",
    "                    par['sex'] = participant[4][0]\n",
    "                    par['age'] = int(participant[3].replace(';', ''))\n",
    "            if l.startswith('*PAR:') or l.startswith('*INV'):\n",
    "                curr_speech = l\n",
    "            elif len(curr_speech) != 0 and not(l.startswith('%') or l.startswith('*')):\n",
    "                curr_speech += l\n",
    "            elif len(curr_speech) > 0:\n",
    "                speech.append(curr_speech)\n",
    "                curr_speech = ''\n",
    "            l = next(f)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    clean_par_speech = []\n",
    "    clean_all_speech = []\n",
    "    speech_time_segments = []\n",
    "    is_par = False\n",
    "    for s in speech:\n",
    "        def _clean(s):\n",
    "            speech_time_segments.append([*map(int, re.search('\\x15(\\d*_\\d*)\\x15', s).groups()[0].split('_'))])\n",
    "            s = re.sub('\\x15\\d*_\\d*\\x15', '', s) # remove time block \n",
    "            s = re.sub('\\[.*\\]', '', s) # remove other speech artifacts [.*]\n",
    "            s = s.strip()\n",
    "            s = re.sub('\\t|\\n|<|>', '', s) # remove tab, new lines, inferred speech??, ampersand, &\n",
    "            return s\n",
    "        \n",
    "        if s.startswith('*PAR:'):\n",
    "            is_par = True\n",
    "        elif s.startswith('*INV:'):\n",
    "            is_par = False\n",
    "            s = re.sub('\\*INV:\\t', '', s) # remove prefix\n",
    "        if is_par:\n",
    "            s = re.sub('\\*PAR:\\t', '', s) # remove prefix    \n",
    "            clean_par_speech.append(_clean(s))\n",
    "        clean_all_speech.append(_clean(s))\n",
    "    \n",
    "    par['speech'] = speech\n",
    "    par['clean_speech'] = clean_all_speech\n",
    "    par['clean_par_speech'] = clean_par_speech\n",
    "    par['joined_all_speech'] = ' '.join(clean_all_speech)\n",
    "    par['joined_all_par_speech'] = ' '.join(clean_par_speech)\n",
    "    \n",
    "    # sentence times\n",
    "    par['per_sent_times'] = [speech_time_segments[i][1] - speech_time_segments[i][0] for i in range(len(speech_time_segments))]\n",
    "    par['total_time'] =  speech_time_segments[-1][1] - speech_time_segments[0][0]\n",
    "    par['time_before_par_speech'] = speech_time_segments[0][0]\n",
    "    par['time_between_sents'] = [0 if i == 0 else max(0, speech_time_segments[i][0] - speech_time_segments[i-1][1]) \n",
    "                                 for i in range(len(speech_time_segments))]\n",
    "    return par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_data():\n",
    "    return _parse_data('../data/train')\n",
    "    \n",
    "def parse_test_data():\n",
    "    return _parse_data('../data/test')\n",
    "\n",
    "def parse_pre_train_data():\n",
    "    return _parse_data('/data/train')\n",
    "\n",
    "def _parse_data(data_dir):\n",
    "    prob_ad_dir = f'{data_dir}/transcription/cd/*'\n",
    "    controls_dir = f'{data_dir}/transcription/cc/*'\n",
    "    \n",
    "    prob_ad = [extract_data(fn) for fn in glob(prob_ad_dir)]\n",
    "    controls = [extract_data(fn) for fn in glob(controls_dir)]\n",
    "    controls_df = pd.DataFrame(controls)\n",
    "    prob_ad_df = pd.DataFrame(prob_ad)\n",
    "    controls_df['ad'] = 0\n",
    "    prob_ad_df['ad'] = 1\n",
    "    df = pd.concat([controls_df, prob_ad_df]).sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = parse_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_speech = train_df.loc[:, ['clean_par_speech', 'ad', 'mmse']].apply(lambda r: pd.DataFrame({'speech_sent': r.clean_par_speech, 'ad': r.ad, 'mmse': r.mmse}), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_sent</th>\n",
       "      <th>ad</th>\n",
       "      <th>mmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can I start ?</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there is a boy on the stool .</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the stool is tipping over .</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the boy is taking cookies out_of the jar .</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;uh the cupboard is open .</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the little boy is standing on a stool and he's...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the little girl's standing there .</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the mother's &amp;st at the sink doing dishes .</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(.) her water's overflowing .</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>that's about it .</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          speech_sent  ad mmse\n",
       "0                                       can I start ?   0   30\n",
       "1                       there is a boy on the stool .   0   30\n",
       "2                         the stool is tipping over .   0   30\n",
       "3          the boy is taking cookies out_of the jar .   0   30\n",
       "4                          &uh the cupboard is open .   0   30\n",
       "..                                                ...  ..  ...\n",
       "7   the little boy is standing on a stool and he's...   1   16\n",
       "8                  the little girl's standing there .   1   16\n",
       "9         the mother's &st at the sink doing dishes .   1   16\n",
       "10                      (.) her water's overflowing .   1   16\n",
       "11                                  that's about it .   1   16\n",
       "\n",
       "[1476 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explode out each segment into AD / control segments\n",
    "pd.concat(segmented_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tran Base-line TfIdf / Random Forest Models / SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'mmse', 'sex', 'age', 'speech', 'clean_speech',\n",
       "       'clean_par_speech', 'joined_all_speech', 'joined_all_par_speech',\n",
       "       'per_sent_times', 'total_time', 'time_before_par_speech',\n",
       "       'time_between_sents', 'ad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv10_avg(score, model, features, labels):\n",
    "    return round(cross_val_score(model, features, labels, cv=10, scoring=score).sum() / 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lines_train_df = train_df.loc[:, ['joined_all_par_speech', 'ad', 'mmse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def baseline_models(input_col):\n",
    "    ## AD Classification Pred\n",
    "    # sklearn pipeline\n",
    "    param_space = {\n",
    "        'vec__max_features': [100, 500, 1000, 2000, 10000],\n",
    "        'vec__stop_words': ['english', None],\n",
    "        'vec__analyzer': ['word', 'char'],\n",
    "        'vec__sublinear_tf': [True, False],\n",
    "        'clf__n_estimators': [100, 200, 500, 700],   # gbdt params\n",
    "        'clf__max_depth': [3, 5, 10],   # gbdt params\n",
    "#         'clf__C': [0.1, 0.5, 1.],               # SVC params\n",
    "#         'clf__kernel': ['rbf', 'sigmoid']       # SVC params\n",
    "    }\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('vec', TfidfVectorizer()),\n",
    "        ('clf', GradientBoostingClassifier())\n",
    "#         ('clf', SVC())\n",
    "    ])\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(train_df[input_col], train_df.ad, random_state=random_state, test_size=0.2)\n",
    "    search = GridSearchCV(pipe, param_space, cv=5, n_jobs=6)\n",
    "    search.fit(train_features, train_labels)\n",
    "\n",
    "    pipe.set_params(**search.best_params_)\n",
    "    print(search.best_params_)\n",
    "    pipe.fit(train_features, train_labels)\n",
    "    preds = pipe.predict(test_features)\n",
    "    print('prec, rec, f1 test', precision_recall_fscore_support(test_labels, preds))\n",
    "    print(f'accu:{cv10_avg(\"accuracy\", pipe, train_df[input_col], train_df.ad)}')\n",
    "    print(f'prec:{cv10_avg(\"precision\", pipe, train_df[input_col], train_df.ad)}')\n",
    "    print(f'rec:{cv10_avg(\"recall\", pipe, train_df[input_col], train_df.ad)}')\n",
    "    print(f'f1:{cv10_avg(\"f1\", pipe, train_df[input_col], train_df.ad)}')\n",
    "\n",
    "    ## MMSE Regression Pred\n",
    "    reg_features, reg_scores = train_df[input_col].iloc[0:36].tolist() + train_df[input_col][37:].tolist(), train_df[train_df.mmse != ''].mmse\n",
    "    train_features, test_features, train_scores, test_scores = train_test_split(reg_features, reg_scores, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    # sklearn pipeline\n",
    "    param_space = {\n",
    "        'vec__max_features': [100, 500, 1000, 2000, 10000],\n",
    "        'vec__stop_words': ['english', None],\n",
    "        'vec__analyzer': ['word', 'char'],\n",
    "        'vec__sublinear_tf': [True, False],\n",
    "        'clf__n_estimators': [100, 200, 500],   # gbdt params\n",
    "        'clf__max_depth': [3, 5, 10, 20, 50],   # gbdt params\n",
    "#         'clf__C': [0.1, 0.5, 1.],               # SVC params\n",
    "#         'clf__kernel': ['rbf', 'sigmoid']       # SVC params\n",
    "    }\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('vec', TfidfVectorizer()),\n",
    "        ('clf', GradientBoostingRegressor())\n",
    "#         ('clf', SVR())\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(pipe, param_space, cv=5, n_jobs=6)\n",
    "    search.fit(train_features, train_scores)\n",
    "\n",
    "    pipe.set_params(**search.best_params_)\n",
    "    print(search.best_params_)\n",
    "    pipe.fit(train_features, train_scores)\n",
    "    preds = pipe.predict(test_features)\n",
    "    print('rmse test:', sqrt(mean_squared_error(test_scores, preds)))\n",
    "    print('rmse cv:', cross_val_score(pipe, reg_features, reg_scores, cv=10, scoring='neg_root_mean_squared_error').sum() / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par speech only\n",
    "baseline_models('joined_all_par_speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 3, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 10000, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "prec, rec, f1 test (array([0.69230769, 0.88888889]), array([0.9       , 0.66666667]), array([0.7826087 , 0.76190476]), array([10, 12]))\n",
      "accu:0.78\n",
      "prec:0.77\n",
      "rec:0.79\n",
      "f1:0.79\n",
      "{'clf__max_depth': 5, 'clf__n_estimators': 500, 'vec__analyzer': 'word', 'vec__max_features': 2000, 'vec__stop_words': 'english', 'vec__sublinear_tf': False}\n",
      "rmse test: 6.382709167789705\n",
      "rmse cv: -5.898423756596404\n"
     ]
    }
   ],
   "source": [
    "# par + inv speech\n",
    "baseline_models('joined_all_speech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (type) model Experimentaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# For DistilroBERTa:\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'distilroberta-base')\n",
    "\n",
    "# BERT Base\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# BERT Large\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-large-uncased')\n",
    "\n",
    "# roBERTa base\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
    "\n",
    "# roBERTa large\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-large')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Only Participant Speech\n",
    "tokenized = train_df.joined_all_par_speech.apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512)))\n",
    "# All (INV + PAR) speech\n",
    "# tokenized = train_df.joined_all_speech.apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512)))\n",
    "\n",
    "# pad so can be treated as one batch\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "# attention mask - zero out attention scores where there is no input to be processed (i.e. is padding)\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape\n",
    "\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# check if multiple GPUs are available\n",
    "multi_gpu = torch.cuda.device_count() > 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(device)\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "last_hidden_states = last_hidden_states[0]\n",
    "if device.type == 'cuda':\n",
    "    last_hidden_states = last_hidden_states.cpu()\n",
    "features = last_hidden_states[:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_transform(features, train_df):\n",
    "    def cv10_avg_nn(score, model, features, labels):\n",
    "        return cv10_avg(score, lr_clf, test_features, train_df.ad)\n",
    "\n",
    "    # AD classification task\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, train_df.ad, random_state=random_state)\n",
    "    parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "    grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
    "    grid_search.fit(train_features, train_labels)\n",
    "    print('best parameters:', grid_search.best_params_)\n",
    "    print('best scores: ', grid_search.best_score_)\n",
    "    lr_clf = LogisticRegression(**grid_search.best_params_)\n",
    "    lr_clf.fit(train_features, train_labels)\n",
    "    preds = lr_clf.predict(test_features)\n",
    "    print('prec, rec, f1 test', precision_recall_fscore_support(test_labels, preds))\n",
    "    print(f'accu:{cv10_avg_nn(\"accuracy\", model)} prec:{cv10_avg_nn(\"precision\")}, rec:{cv10_avg_nn(\"recall\")}, f1:{cv10_avg_nn(\"f1\")}')\n",
    "          \n",
    "    # MMSE regression task\n",
    "    # remove missing row\n",
    "    reg_features, reg_scores = np.vstack([features[0:36], features[37:]]), train_df[train_df.mmse != ''].mmse\n",
    "    train_features, test_features, train_scores, test_scores = train_test_split(reg_features, reg_scores, random_state=random_state)\n",
    "    parameters = {'alpha': np.linspace(0.001, 100, 20)}\n",
    "    grid_search = GridSearchCV(Ridge(), parameters)\n",
    "    grid_search.fit(train_features, train_scores)\n",
    "    print('best parameters:', grid_search.best_params_)\n",
    "    print('best scores: ', grid_search.best_score_)\n",
    "    reg_model = Ridge(**grid_search.best_params_)\n",
    "    reg_model.fit(train_features, train_scores)\n",
    "    preds = reg_model.predict(test_features)\n",
    "    print('rmse test:', sqrt(mean_squared_error(test_scores, preds)))\n",
    "    print('rmse cv:', cross_val_score(reg_model, reg_features, reg_scores, cv=10, scoring='neg_root_mean_squared_error').sum() / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Features\n",
    "bert_features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time features\n",
    "# - Embed time total time taken \n",
    "# - parse time blocks, take first and last\n",
    "# - Embed total time taken per sentence\n",
    "# - Time before starting speech\n",
    "# - Time in between each sentence\n",
    "# - Average / min / max / median time of sentence\n",
    "time_dims = train_df.loc[:, ['total_time', 'time_before_par_speech', 'time_between_sents', 'per_sent_times']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dims['avg_betweeen_sents'] = time_dims.time_between_sents.apply(lambda t: round(sum(t) / len(t)))\n",
    "time_dims['max'] = time_dims.time_between_sents.apply(max)\n",
    "time_dims['min'] = time_dims.time_between_sents.apply(min)\n",
    "time_dims_eng = time_dims.drop('time_between_sents', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_before_par_speech</th>\n",
       "      <th>time_between_sents</th>\n",
       "      <th>per_sent_times</th>\n",
       "      <th>avg_betweeen_sents</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28249</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[7580, 7580, 2750, 2750, 1670, 1670, 1277, 127...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39304</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3700, 2167, 2633, 2633, 3795, 3795, 2785, 278...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108061</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2475, 3757, 7084, 7084, 7681, 7681, 3657, 365...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70330</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[997, 831, 1014, 1014, 3958, 3958, 3102, 3102,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84322</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1829, 1064, 3271, 3806, 770, 770, 14216, 1421...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>190561</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2913, 11657, 11657, 14986, 14986, 12979, 1297...</td>\n",
       "      <td>49</td>\n",
       "      <td>732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>56600</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1829, 2013, 2013, 558, 558, 1919, 1919, 12302...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>88250</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1573, 5913, 5913, 2614, 2614, 4376, 4376, 652...</td>\n",
       "      <td>439</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>81475</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1853, 6097, 6097, 1512, 1512, 7161, 7161, 610...</td>\n",
       "      <td>34</td>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>44683</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1813, 620, 620, 1757, 1757, 6500, 6500, 1764,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_time  time_before_par_speech  \\\n",
       "0         28249                       0   \n",
       "1         39304                       0   \n",
       "2        108061                       0   \n",
       "3         70330                       0   \n",
       "4         84322                       0   \n",
       "..          ...                     ...   \n",
       "103      190561                       0   \n",
       "104       56600                       0   \n",
       "105       88250                       0   \n",
       "106       81475                       0   \n",
       "107       44683                       0   \n",
       "\n",
       "                                    time_between_sents  \\\n",
       "0        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    [0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "..                                                 ...   \n",
       "103  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "104  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "105  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "106  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "107  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        per_sent_times  avg_betweeen_sents  \\\n",
       "0    [7580, 7580, 2750, 2750, 1670, 1670, 1277, 127...                   0   \n",
       "1    [3700, 2167, 2633, 2633, 3795, 3795, 2785, 278...                   0   \n",
       "2    [2475, 3757, 7084, 7084, 7681, 7681, 3657, 365...                   0   \n",
       "3    [997, 831, 1014, 1014, 3958, 3958, 3102, 3102,...                   0   \n",
       "4    [1829, 1064, 3271, 3806, 770, 770, 14216, 1421...                   3   \n",
       "..                                                 ...                 ...   \n",
       "103  [2913, 11657, 11657, 14986, 14986, 12979, 1297...                  49   \n",
       "104  [1829, 2013, 2013, 558, 558, 1919, 1919, 12302...                   0   \n",
       "105  [1573, 5913, 5913, 2614, 2614, 4376, 4376, 652...                 439   \n",
       "106  [1853, 6097, 6097, 1512, 1512, 7161, 7161, 610...                  34   \n",
       "107  [1813, 620, 620, 1757, 1757, 6500, 6500, 1764,...                   0   \n",
       "\n",
       "       max  min  \n",
       "0        0    0  \n",
       "1        0    0  \n",
       "2        0    0  \n",
       "3        0    0  \n",
       "4      100    0  \n",
       "..     ...  ...  \n",
       "103    732    0  \n",
       "104      0    0  \n",
       "105  10520    0  \n",
       "106    897    0  \n",
       "107      0    0  \n",
       "\n",
       "[108 rows x 7 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.clean_par_speech.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = StandardScaler().fit_transform(time_dims_eng.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForADClassification(torch.nn.Module):\n",
    "    def __init__(self, bertModel, time_dims,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bertModel = bertModel\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        \n",
    "        # separate Linear for OHE of time\n",
    "        bert_hidden_dim = self.bertModel\n",
    "    \n",
    "        self.classifier = nn.Linear()\n",
    "    \n",
    "    def forward(input_ids, attention_mask):\n",
    "        last_hidden_states = self.bertModel(input_ids, attention_mask=attention_mask)\n",
    "        features = last_hidden_states[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all features\n",
    "features = np.hstack([bert_features, time_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:distil_bert]",
   "language": "python",
   "name": "conda-env-distil_bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
