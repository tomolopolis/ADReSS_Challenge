{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interspeech 2020 Challenge\n",
    "Deadline: May 8th submission of predictions and paper.\n",
    "\n",
    "Main Webpage: http://www.interspeech2020.org/index.php?m=content&c=index&a=lists&catid=66\n",
    "\n",
    "Challenge Webpage: http://www.homepages.ed.ac.uk/sluzfil/ADReSS/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Plan\n",
    "Only using the transcripts:\n",
    "- [x] Simple clean and join all sentences, classifiy using DistillBERT, (BERT), (RoBERTa)   ## Done\n",
    "\n",
    "## Further Feature Engineering:\n",
    "### Time dimension\n",
    "- Embed time total time taken - parse time blocks, take first and last\n",
    "- Embed total time taken per sentence\n",
    "- Time before starting speech\n",
    "- Time in between each sentence\n",
    "- Average / min / max / median time of sentence\n",
    "- use of special characters\n",
    "- number of sentences spoken\n",
    "\n",
    "### Linguistic Features\n",
    "- Embed special character tokens in speech, pauses etc. (not sure if this needed, tokenzier / and\n",
    "- classify on a sentence level??\n",
    "- Also use the Interviewer INV, questions / speech / time...\n",
    "- Use POS Tags: as OHE vector\n",
    "\n",
    "## Demographics\n",
    "- Gender\n",
    "- Age\n",
    "\n",
    "## Fine-tuning BERT(-esque) models on spontaneous speech datasets\n",
    "- fine-tune and re-classify using other spontaneous speech datasets: \n",
    "\n",
    "### Further work on\n",
    "- Analysis of what roBERTa has actually learned in the attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ad_dir = '../train/transcription/cd/*'\n",
    "controls_dir = '../train/transcription/cc/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_data(file_name):\n",
    "    par = {}\n",
    "    par['id'] = file_name.split('/')[-1].split('.cha')[0]\n",
    "    f = iter(open(file_name))\n",
    "    l = next(f)\n",
    "    speech = []\n",
    "    try:\n",
    "        curr_speech = ''\n",
    "        while (True):\n",
    "            if l.startswith('@ID'):\n",
    "                participant = [i.strip() for i in l.split('|')]\n",
    "                if participant[2] == 'PAR':\n",
    "                    par['mmse'] = participant[8]\n",
    "                    par['sex'] = participant[4][0]\n",
    "                    par['age'] = int(participant[3].replace(';', ''))\n",
    "            if l.startswith('*PAR:'):\n",
    "                curr_speech = l\n",
    "            elif len(curr_speech) != 0 and not(l.startswith('%') or l.startswith('*')):\n",
    "                curr_speech += l\n",
    "            elif len(curr_speech) > 0:\n",
    "                speech.append(curr_speech)\n",
    "                curr_speech = ''\n",
    "            l = next(f)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    clean_speech = []\n",
    "    speech_time_segments = []\n",
    "    for s in speech:\n",
    "        s = re.sub('\\*PAR:\\t', '', s) # remove prefix    \n",
    "        speech_time_segments.append([*map(int, re.search('\\x15(\\d*_\\d*)\\x15', s).groups()[0].split('_'))])\n",
    "        s = re.sub('\\x15\\d*_\\d*\\x15', '', s) # remove time block \n",
    "        s = re.sub('\\[.*\\]', '', s) # remove other speech artifacts [.*]\n",
    "        s = s.strip()\n",
    "        s = re.sub('\\t|\\n|<|>', '', s) # remove tab, new lines, inferred speech??, ampersand, &\n",
    "        clean_speech.append(s)\n",
    "    par['speech'] = speech\n",
    "    par['clean_speech'] = clean_speech\n",
    "    par['all_clean_speech'] = ' '.join(clean_speech)\n",
    "    \n",
    "    # sentence times\n",
    "    par['per_sent_times'] = speech_time_segments\n",
    "    par['total_time'] =  speech_time_segments[-1][1] - speech_time_segments[0][0]\n",
    "    par['time_before_par_speech'] = speech_time_segments[0][0]\n",
    "    par['time_between_sents'] = [0 if i == 0 else max(0, speech_time_segments[i][0] - speech_time_segments[i-1][1]) \n",
    "                                 for i in range(len(speech_time_segments))]\n",
    "    return par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for l in open('train/transcription/cc/S030.cha'):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_data(train=True):\n",
    "    data_dir = 'train'\n",
    "    if not train:\n",
    "        data_dir = 'test'\n",
    "    \n",
    "    prob_ad_dir = f'{data_dir}/transcription/cd/*'\n",
    "    controls_dir = f'{data_dir}/transcription/cc/*'\n",
    "    \n",
    "    controls = [extract_data(fn) for fn in glob(prob_ad_dir)]\n",
    "    prob_ad = [extract_data(fn) for fn in glob(controls_dir)]\n",
    "    controls_df = pd.DataFrame(controls)\n",
    "    prob_ad_df = pd.DataFrame(prob_ad)\n",
    "    controls_df['ad'] = 0\n",
    "    prob_ad_df['ad'] = 1\n",
    "    df = pd.concat([controls_df, prob_ad_df]).sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = parse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mmse</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>speech</th>\n",
       "      <th>clean_speech</th>\n",
       "      <th>all_clean_speech</th>\n",
       "      <th>per_sent_times</th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_before_par_speech</th>\n",
       "      <th>time_between_sents</th>\n",
       "      <th>ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S009</td>\n",
       "      <td>30</td>\n",
       "      <td>m</td>\n",
       "      <td>67</td>\n",
       "      <td>[*PAR:\\ta boy is taking &amp;uh cookies from the c...</td>\n",
       "      <td>[a boy is taking &amp;uh cookies from the cookie j...</td>\n",
       "      <td>a boy is taking &amp;uh cookies from the cookie ja...</td>\n",
       "      <td>[[2460, 8778], [8778, 11522], [11522, 14064], ...</td>\n",
       "      <td>51190</td>\n",
       "      <td>2460</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1609, 0, 0, 554]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S089</td>\n",
       "      <td>18</td>\n",
       "      <td>m</td>\n",
       "      <td>65</td>\n",
       "      <td>[*PAR:\\tso she will find her . \u00150_2741\u0015\\n, *PA...</td>\n",
       "      <td>[so she will find her ., and xxx the mother wa...</td>\n",
       "      <td>so she will find her . and xxx the mother wash...</td>\n",
       "      <td>[[0, 2741], [2741, 6461], [6461, 12031], [1203...</td>\n",
       "      <td>59237</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 2935, 1257, 0, 0, 0, 4857]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S017</td>\n",
       "      <td>28</td>\n",
       "      <td>f</td>\n",
       "      <td>65</td>\n",
       "      <td>[*PAR:\\twell I see the mother doing the dishes...</td>\n",
       "      <td>[well I see the mother doing the dishes ., the...</td>\n",
       "      <td>well I see the mother doing the dishes . the s...</td>\n",
       "      <td>[[0, 1979], [1979, 4792], [4792, 15051], [1505...</td>\n",
       "      <td>26442</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S154</td>\n",
       "      <td>20</td>\n",
       "      <td>f</td>\n",
       "      <td>65</td>\n",
       "      <td>[*PAR:\\tyou want me to tell you ? [+ exc] \u0015536...</td>\n",
       "      <td>[you want me to tell you ?, okay &amp;uh the boy's...</td>\n",
       "      <td>you want me to tell you ? okay &amp;uh the boy's g...</td>\n",
       "      <td>[[5361, 6358], [6358, 9618], [9618, 12111], [1...</td>\n",
       "      <td>25602</td>\n",
       "      <td>5361</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S103</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>64</td>\n",
       "      <td>[*PAR:\\tthe boy's &amp;uh fallin(g) off the stool ...</td>\n",
       "      <td>[the boy's &amp;uh fallin(g) off the stool ., the ...</td>\n",
       "      <td>the boy's &amp;uh fallin(g) off the stool . the  t...</td>\n",
       "      <td>[[6035, 13351], [13351, 17373], [17373, 21502]...</td>\n",
       "      <td>52252</td>\n",
       "      <td>6035</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 12702, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>S082</td>\n",
       "      <td>11</td>\n",
       "      <td>m</td>\n",
       "      <td>66</td>\n",
       "      <td>[*PAR:\\t&amp;=clears:throat well &amp;=clears:throat &amp;...</td>\n",
       "      <td>[&amp;=clears:throat well &amp;=clears:throat &amp;uh the ...</td>\n",
       "      <td>&amp;=clears:throat well &amp;=clears:throat &amp;uh the k...</td>\n",
       "      <td>[[2913, 14570], [14570, 29556], [29556, 42535]...</td>\n",
       "      <td>186681</td>\n",
       "      <td>2913</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1177, 575, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>S003</td>\n",
       "      <td>29</td>\n",
       "      <td>f</td>\n",
       "      <td>69</td>\n",
       "      <td>[*PAR:\\tokay . [+ exc] \u00150_1074\u0015\\n, *PAR:\\tther...</td>\n",
       "      <td>[okay ., there's a little boy and he's getting...</td>\n",
       "      <td>okay . there's a little boy and he's getting  ...</td>\n",
       "      <td>[[0, 1074], [1074, 6133], [6133, 16452], [1645...</td>\n",
       "      <td>67484</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 2549, 0, 382, 0, 0, 0, 0, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>S068</td>\n",
       "      <td>29</td>\n",
       "      <td>m</td>\n",
       "      <td>50</td>\n",
       "      <td>[*PAR:\\tthe &amp;uh water's running on the floor ....</td>\n",
       "      <td>[the &amp;uh water's running on the floor ., boy's...</td>\n",
       "      <td>the &amp;uh water's running on the floor . boy's t...</td>\n",
       "      <td>[[0, 2291], [2291, 6296], [6296, 10256], [1025...</td>\n",
       "      <td>31269</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 9533]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>S156</td>\n",
       "      <td>13</td>\n",
       "      <td>f</td>\n",
       "      <td>71</td>\n",
       "      <td>[*PAR:\\tmhm . [+ exc] \u00151200_1800\u0015\\n, *PAR:\\twe...</td>\n",
       "      <td>[mhm ., well this one is in the cookie jar ., ...</td>\n",
       "      <td>mhm . well this one is in the cookie jar . and...</td>\n",
       "      <td>[[1200, 1800], [4100, 9000], [10097, 14770], [...</td>\n",
       "      <td>67311</td>\n",
       "      <td>1200</td>\n",
       "      <td>[0, 2300, 1097, 0, 0, 0, 0, 0, 2845, 550, 7661...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>S019</td>\n",
       "      <td>27</td>\n",
       "      <td>f</td>\n",
       "      <td>57</td>\n",
       "      <td>[*PAR:\\tokay . [+ exc] \u00157005_10322\u0015\\n, *PAR:\\t...</td>\n",
       "      <td>[okay ., well the mother is drying the dishes ...</td>\n",
       "      <td>okay . well the mother is drying the dishes . ...</td>\n",
       "      <td>[[7005, 10322], [10322, 13948], [13948, 17418]...</td>\n",
       "      <td>47176</td>\n",
       "      <td>7005</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1060, 0, 1091, 6227]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id mmse sex  age                                             speech  \\\n",
       "0    S009   30   m   67  [*PAR:\\ta boy is taking &uh cookies from the c...   \n",
       "1    S089   18   m   65  [*PAR:\\tso she will find her . \u00150_2741\u0015\\n, *PA...   \n",
       "2    S017   28   f   65  [*PAR:\\twell I see the mother doing the dishes...   \n",
       "3    S154   20   f   65  [*PAR:\\tyou want me to tell you ? [+ exc] \u0015536...   \n",
       "4    S103   27   m   64  [*PAR:\\tthe boy's &uh fallin(g) off the stool ...   \n",
       "..    ...  ...  ..  ...                                                ...   \n",
       "103  S082   11   m   66  [*PAR:\\t&=clears:throat well &=clears:throat &...   \n",
       "104  S003   29   f   69  [*PAR:\\tokay . [+ exc] \u00150_1074\u0015\\n, *PAR:\\tther...   \n",
       "105  S068   29   m   50  [*PAR:\\tthe &uh water's running on the floor ....   \n",
       "106  S156   13   f   71  [*PAR:\\tmhm . [+ exc] \u00151200_1800\u0015\\n, *PAR:\\twe...   \n",
       "107  S019   27   f   57  [*PAR:\\tokay . [+ exc] \u00157005_10322\u0015\\n, *PAR:\\t...   \n",
       "\n",
       "                                          clean_speech  \\\n",
       "0    [a boy is taking &uh cookies from the cookie j...   \n",
       "1    [so she will find her ., and xxx the mother wa...   \n",
       "2    [well I see the mother doing the dishes ., the...   \n",
       "3    [you want me to tell you ?, okay &uh the boy's...   \n",
       "4    [the boy's &uh fallin(g) off the stool ., the ...   \n",
       "..                                                 ...   \n",
       "103  [&=clears:throat well &=clears:throat &uh the ...   \n",
       "104  [okay ., there's a little boy and he's getting...   \n",
       "105  [the &uh water's running on the floor ., boy's...   \n",
       "106  [mhm ., well this one is in the cookie jar ., ...   \n",
       "107  [okay ., well the mother is drying the dishes ...   \n",
       "\n",
       "                                      all_clean_speech  \\\n",
       "0    a boy is taking &uh cookies from the cookie ja...   \n",
       "1    so she will find her . and xxx the mother wash...   \n",
       "2    well I see the mother doing the dishes . the s...   \n",
       "3    you want me to tell you ? okay &uh the boy's g...   \n",
       "4    the boy's &uh fallin(g) off the stool . the  t...   \n",
       "..                                                 ...   \n",
       "103  &=clears:throat well &=clears:throat &uh the k...   \n",
       "104  okay . there's a little boy and he's getting  ...   \n",
       "105  the &uh water's running on the floor . boy's t...   \n",
       "106  mhm . well this one is in the cookie jar . and...   \n",
       "107  okay . well the mother is drying the dishes . ...   \n",
       "\n",
       "                                        per_sent_times  total_time  \\\n",
       "0    [[2460, 8778], [8778, 11522], [11522, 14064], ...       51190   \n",
       "1    [[0, 2741], [2741, 6461], [6461, 12031], [1203...       59237   \n",
       "2    [[0, 1979], [1979, 4792], [4792, 15051], [1505...       26442   \n",
       "3    [[5361, 6358], [6358, 9618], [9618, 12111], [1...       25602   \n",
       "4    [[6035, 13351], [13351, 17373], [17373, 21502]...       52252   \n",
       "..                                                 ...         ...   \n",
       "103  [[2913, 14570], [14570, 29556], [29556, 42535]...      186681   \n",
       "104  [[0, 1074], [1074, 6133], [6133, 16452], [1645...       67484   \n",
       "105  [[0, 2291], [2291, 6296], [6296, 10256], [1025...       31269   \n",
       "106  [[1200, 1800], [4100, 9000], [10097, 14770], [...       67311   \n",
       "107  [[7005, 10322], [10322, 13948], [13948, 17418]...       47176   \n",
       "\n",
       "     time_before_par_speech  \\\n",
       "0                      2460   \n",
       "1                         0   \n",
       "2                         0   \n",
       "3                      5361   \n",
       "4                      6035   \n",
       "..                      ...   \n",
       "103                    2913   \n",
       "104                       0   \n",
       "105                       0   \n",
       "106                    1200   \n",
       "107                    7005   \n",
       "\n",
       "                                    time_between_sents  ad  \n",
       "0               [0, 0, 0, 0, 0, 0, 0, 1609, 0, 0, 554]   1  \n",
       "1        [0, 0, 0, 0, 0, 0, 2935, 1257, 0, 0, 0, 4857]   0  \n",
       "2                          [0, 0, 0, 0, 0, 0, 0, 0, 0]   1  \n",
       "3                                [0, 0, 0, 0, 0, 0, 0]   0  \n",
       "4                      [0, 0, 0, 0, 0, 0, 0, 12702, 0]   0  \n",
       "..                                                 ...  ..  \n",
       "103  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1177, 575, 0...   0  \n",
       "104  [0, 0, 0, 0, 0, 0, 2549, 0, 382, 0, 0, 0, 0, 0...   1  \n",
       "105                              [0, 0, 0, 0, 0, 9533]   1  \n",
       "106  [0, 2300, 1097, 0, 0, 0, 0, 0, 2845, 550, 7661...   0  \n",
       "107         [0, 0, 0, 0, 0, 0, 0, 1060, 0, 1091, 6227]   1  \n",
       "\n",
       "[108 rows x 12 columns]"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (type) model Experimentaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Distill_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Want BERT instead of distilBERT? Uncomment the following line:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fc4bbc4d6445759a0c054aa1bcc1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277c24c3bb30455cac0ccbaf7de231eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2fe56e7d354798a9a31c4dbd1807bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=524.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a4ba8297014d43ad32fcfbf4117962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Want BERT instead of distilBERT? Uncomment the following line:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df.all_clean_speech.apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    483\n",
       "1      363\n",
       "11     329\n",
       "83     328\n",
       "12     298\n",
       "      ... \n",
       "61      60\n",
       "41      56\n",
       "94      43\n",
       "37      40\n",
       "48      39\n",
       "Name: all_clean_speech, Length: 108, dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkn_inds = []\n",
    "for sent in df.all_clean_speech:\n",
    "    tkn_inds.append(tokenizer.encode(sent, add_special_tokens=True, max_length=512))\n",
    "tokenized.apply(len).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pad so can be treated as one batch\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "# attention mask - zero out attention scores where there is no input to be processed (i.e. is padding)\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distil_BERT Embed / BERT Embed / roBERTa Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# check if multiple GPUs are available\n",
    "multi_gpu = torch.cuda.device_count() > 1:\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "    input_ids.to(device)\n",
    "    attention_mask.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 768)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 483, 768])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Features\n",
    "bert_features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time features\n",
    "# - Embed time total time taken \n",
    "# - parse time blocks, take first and last\n",
    "# - Embed total time taken per sentence\n",
    "# - Time before starting speech\n",
    "# - Time in between each sentence\n",
    "# - Average / min / max / median time of sentence\n",
    "time_dims = train_df.loc[:, ['total_time', 'time_before_par_speech', 'time_between_sents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_dims['avg_betweeen_sents'] = time_dims.time_between_sents.apply(lambda t: round(sum(t) / len(t)))\n",
    "# time_dims['max'] = time_dims.time_between_sents.apply(max)\n",
    "# time_dims['min'] = time_dims.time_between_sents.apply(min)\n",
    "time_dims_eng = time_dims.drop('time_between_sents', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = StandardScaler().fit_transform(time_dims_eng.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all features\n",
    "features = np.hstack([bert_features, time_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, df.ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 89.4736947368421}\n",
      "best scores:  0.7661764705882353\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "grid_search = GridSearchCV(LogisticRegression(penalty='L2'), parameters)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "print('best parameters:', grid_search.best_params_)\n",
    "print('best scores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=89.4736947368421, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(**grid_search.best_params_)\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6296296296296297"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.5625, 0.6428571428571429, None)"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(preds, test_labels, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out-Of-The-Box Distill BERT and BERT achieve scores:\n",
    "Distill BERT: 0.74\n",
    "\n",
    "BERT: 0.77\n",
    "\n",
    "RoBERTA: 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.542 (+/- 0.23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:distil_bert]",
   "language": "python",
   "name": "conda-env-distil_bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
