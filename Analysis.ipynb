{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import regex as re\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, mean_squared_error, accuracy_score\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFClassifier, XGBRegressor, XGBRFRegressor\n",
    "from xgboost import plot_importance\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interspeech 2020 Challenge\n",
    "Deadline: May 8th submission of predictions and paper.\n",
    "\n",
    "Main Webpage: http://www.interspeech2020.org/index.php?m=content&c=index&a=lists&catid=66\n",
    "\n",
    "Challenge Webpage: http://www.homepages.ed.ac.uk/sluzfil/ADReSS/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Plan\n",
    "Only using the transcripts:\n",
    "- [x] Simple clean and join all sentences, classifiy using DistillBERT, (BERT), (RoBERTa)   ## Done\n",
    "\n",
    "## Further Feature Engineering:\n",
    "### Time dimension\n",
    "- Embed time total time taken - parse time blocks, take first and last\n",
    "- Embed total time taken per sentence\n",
    "- Time before starting speech\n",
    "- Time in between each sentence\n",
    "- Average / min / max / median time of sentence\n",
    "- use of special characters\n",
    "- number of sentences spoken\n",
    "\n",
    "### Linguistic Features\n",
    "- Embed special character tokens in speech, pauses etc. (not sure if this needed, tokenzier / and\n",
    "- classify on a sentence level??\n",
    "- Also use the Interviewer INV, questions / speech / time...\n",
    "- Use POS Tags: as OHE vector\n",
    "\n",
    "## Demographics\n",
    "- Gender\n",
    "- Age\n",
    "\n",
    "## Fine-tuning BERT(-esque) models on spontaneous speech datasets\n",
    "- fine-tune and re-classify using other spontaneous speech datasets: \n",
    "\n",
    "### Further work on\n",
    "- Analysis of what roBERTa has actually learned in the attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ad_dir = '../train/transcription/cd/*'\n",
    "controls_dir = '../train/transcription/cc/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_name):\n",
    "    par = {}\n",
    "    par['id'] = file_name.split('/')[-1].split('.cha')[0]\n",
    "    f = iter(open(file_name))\n",
    "    l = next(f)\n",
    "    speech = []\n",
    "    try:\n",
    "        curr_speech = ''\n",
    "        while (True):\n",
    "            if l.startswith('@ID'):\n",
    "                participant = [i.strip() for i in l.split('|')]\n",
    "                if participant[2] == 'PAR':\n",
    "                    par['mmse'] = '' if len(participant[8]) == 0 else float(participant[8])\n",
    "                    par['sex'] = participant[4][0]\n",
    "                    par['age'] = int(participant[3].replace(';', ''))\n",
    "            if l.startswith('*PAR:') or l.startswith('*INV'):\n",
    "                curr_speech = l\n",
    "            elif len(curr_speech) != 0 and not(l.startswith('%') or l.startswith('*')):\n",
    "                curr_speech += l\n",
    "            elif len(curr_speech) > 0:\n",
    "                speech.append(curr_speech)\n",
    "                curr_speech = ''\n",
    "            l = next(f)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    clean_par_speech = []\n",
    "    clean_all_speech = []\n",
    "    par_speech_time_segments = []\n",
    "    all_speech_time_segments = []\n",
    "    is_par = False\n",
    "    for s in speech:\n",
    "        def _parse_time(s):\n",
    "            return [*map(int, re.search('\\x15(\\d*_\\d*)\\x15', s).groups()[0].split('_'))]\n",
    "        \n",
    "        def _clean(s):\n",
    "            s = re.sub('\\x15\\d*_\\d*\\x15', '', s) # remove time block \n",
    "            s = re.sub('\\[.*\\]', '', s) # remove other speech artifacts [.*]\n",
    "            s = s.strip()\n",
    "            s = re.sub('\\t|\\n|<|>', '', s) # remove tab, new lines, inferred speech??, ampersand, &\n",
    "            return s\n",
    "        \n",
    "        if s.startswith('*PAR:'):\n",
    "            is_par = True\n",
    "        elif s.startswith('*INV:'):\n",
    "            is_par = False\n",
    "            s = re.sub('\\*INV:\\t', '', s) # remove prefix\n",
    "        if is_par:\n",
    "            s = re.sub('\\*PAR:\\t', '', s) # remove prefix    \n",
    "            par_speech_time_segments.append(_parse_time(s))\n",
    "            clean_par_speech.append(_clean(s))\n",
    "        all_speech_time_segments.append(_parse_time(s))\n",
    "        clean_all_speech.append(_clean(s))\n",
    "        \n",
    "    par['speech'] = speech\n",
    "    par['clean_speech'] = clean_all_speech\n",
    "    par['clean_par_speech'] = clean_par_speech\n",
    "    par['joined_all_speech'] = ' '.join(clean_all_speech)\n",
    "    par['joined_all_par_speech'] = ' '.join(clean_par_speech)\n",
    "    \n",
    "    # sentence times\n",
    "    par['per_sent_times'] = [par_speech_time_segments[i][1] - par_speech_time_segments[i][0] for i in range(len(par_speech_time_segments))]\n",
    "    par['total_time'] =  par_speech_time_segments[-1][1] - par_speech_time_segments[0][0]\n",
    "    par['time_before_par_speech'] = par_speech_time_segments[0][0]\n",
    "    par['time_between_sents'] = [0 if i == 0 else max(0, par_speech_time_segments[i][0] - par_speech_time_segments[i-1][1]) \n",
    "                                 for i in range(len(par_speech_time_segments))]\n",
    "    return par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_data():\n",
    "    return _parse_data('../data/train')\n",
    "    \n",
    "def parse_test_data():\n",
    "    return _parse_data('../data/test')\n",
    "\n",
    "def parse_pre_train_data():\n",
    "    return _parse_data('/data/train')\n",
    "\n",
    "def _parse_data(data_dir):\n",
    "    prob_ad_dir = f'{data_dir}/transcription/cd/*'\n",
    "    controls_dir = f'{data_dir}/transcription/cc/*'\n",
    "    \n",
    "    prob_ad = [extract_data(fn) for fn in glob(prob_ad_dir)]\n",
    "    controls = [extract_data(fn) for fn in glob(controls_dir)]\n",
    "    controls_df = pd.DataFrame(controls)\n",
    "    prob_ad_df = pd.DataFrame(prob_ad)\n",
    "    controls_df['ad'] = 0\n",
    "    prob_ad_df['ad'] = 1\n",
    "    df = pd.concat([controls_df, prob_ad_df]).sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = parse_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-line TF-IDF -> GBDT / SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv10_avg(score, model, features, labels):\n",
    "    return round(cross_val_score(model, features, labels, cv=10, scoring=score).sum() / 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_models(text: pd.Series, labels: list, mmse: list, xgb=True, shuffle=True, print_stats=True):\n",
    "    ## AD Classification Pred\n",
    "    # sklearn pipeline\n",
    "    param_space = {\n",
    "        'vec__max_features': [100, 500, 1000, 2000, 10000],\n",
    "        'vec__stop_words': ['english', None],\n",
    "        'vec__analyzer': ['word', 'char'],\n",
    "        'vec__sublinear_tf': [True, False]       \n",
    "    }    \n",
    "    if xgb:\n",
    "        param_space['clf__n_estimators'] = [100, 200, 500]  \n",
    "        param_space['clf__max_depth'] = [3, 5, 10]\n",
    "    else:\n",
    "        param_space['clf__C'] = [0.1, 0.5, 1.]              \n",
    "        param_space['clf__kernel'] = ['rbf', 'sigmoid']    \n",
    "\n",
    "    clf_pipe = Pipeline([\n",
    "        ('vec', TfidfVectorizer()),\n",
    "        ('clf', XGBClassifier(probability=True)) if xgb else ('clf', SVC(probability=True))\n",
    "    ])\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(text, labels, random_state=random_state, test_size=0.2, shuffle=shuffle)\n",
    "    search = GridSearchCV(clf_pipe, param_space, cv=5, n_jobs=6)\n",
    "    search.fit(train_features, train_labels)\n",
    "\n",
    "    clf_pipe.set_params(**search.best_params_)\n",
    "    print(search.best_params_)\n",
    "    clf_pipe.fit(train_features, train_labels)\n",
    "    preds = clf_pipe.predict(test_features)\n",
    "    if print_stats:\n",
    "        print('prec, rec, f1 test', precision_recall_fscore_support(test_labels, preds))\n",
    "        print(f'accu:{cv10_avg(\"accuracy\", clf_pipe, text, labels)}')\n",
    "        print(f'prec:{cv10_avg(\"precision\", clf_pipe, text, labels)}')\n",
    "        print(f'rec:{cv10_avg(\"recall\", clf_pipe, text, labels)}')\n",
    "        print(f'f1:{cv10_avg(\"f1\", clf_pipe, text, labels)}')\n",
    "\n",
    "    ## MMSE Regression Pred\n",
    "    reg_features, reg_scores = text.drop([i for i, s in enumerate(mmse) if s == '']).reset_index(drop=True), [s for s in mmse if s != '']\n",
    "    train_features, test_features, train_scores, test_scores = train_test_split(reg_features, reg_scores, random_state=random_state, test_size=0.2, shuffle=shuffle)\n",
    "\n",
    "    # sklearn pipeline\n",
    "    param_space = {\n",
    "        'vec__max_features': [100, 500, 1000, 2000, 10000],\n",
    "        'vec__stop_words': ['english', None],\n",
    "        'vec__analyzer': ['word', 'char'],\n",
    "        'vec__sublinear_tf': [True, False]\n",
    "    }    \n",
    "    if xgb:\n",
    "        param_space['clf__n_estimators'] = [100, 200, 500]  \n",
    "        param_space['clf__max_depth'] = [3, 5, 10]  \n",
    "    else:\n",
    "        param_space['clf__C'] = [0.1, 0.5, 1.]              \n",
    "        param_space['clf__kernel'] = ['rbf', 'sigmoid']   \n",
    "\n",
    "    rgs_pipe = Pipeline([\n",
    "        ('vec', TfidfVectorizer()),\n",
    "        ('clf', XGBRegressor()) if xgb else ('clf', SVR())\n",
    "    ])\n",
    "\n",
    "    search = GridSearchCV(rgs_pipe, param_space, cv=5, n_jobs=6)\n",
    "    search.fit(train_features, train_scores)\n",
    "\n",
    "    rgs_pipe.set_params(**search.best_params_)\n",
    "    print(search.best_params_)\n",
    "    rgs_pipe.fit(train_features, train_scores)\n",
    "    preds = rgs_pipe.predict(test_features)\n",
    "    if print_stats:\n",
    "        print('rmse test:', sqrt(mean_squared_error(test_scores, preds)))\n",
    "        print('rmse cv:', cross_val_score(rgs_pipe, reg_features, reg_scores, cv=10, scoring='neg_root_mean_squared_error').sum() / 10)\n",
    "\n",
    "    return clf_pipe, rgs_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.0, 'clf__kernel': 'rbf', 'vec__analyzer': 'word', 'vec__max_features': 1000, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "prec, rec, f1 test (array([0.84615385, 1.        ]), array([1.        , 0.81818182]), array([0.91666667, 0.9       ]), array([11, 11]))\n",
      "accu:0.86\n",
      "prec:0.91\n",
      "rec:0.84\n",
      "f1:0.85\n",
      "{'clf__C': 1.0, 'clf__kernel': 'sigmoid', 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': 'english', 'vec__sublinear_tf': True}\n",
      "rmse test: 6.715101139865216\n",
      "rmse cv: -5.828961412118949\n"
     ]
    }
   ],
   "source": [
    "# SVM - par speech only\n",
    "clf_svm, rgs_svm = baseline_models(train_df.joined_all_par_speech, train_df.ad,  train_df.mmse, xgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.0, 'clf__kernel': 'rbf', 'vec__analyzer': 'word', 'vec__max_features': 500, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "prec, rec, f1 test (array([0.83333333, 0.9       ]), array([0.90909091, 0.81818182]), array([0.86956522, 0.85714286]), array([11, 11]))\n",
      "accu:0.88\n",
      "prec:0.92\n",
      "rec:0.87\n",
      "f1:0.87\n",
      "{'clf__C': 1.0, 'clf__kernel': 'sigmoid', 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "rmse test: 6.674597551339369\n",
      "rmse cv: -5.734230349579695\n"
     ]
    }
   ],
   "source": [
    "# SVM - par + inv speech\n",
    "clf_svm, rgs_svm = baseline_models(train_df.joined_all_speech, train_df.ad, train_df.mmse, xgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 5, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': 'english', 'vec__sublinear_tf': False}\n",
      "prec, rec, f1 test (array([0.8, 1. ]), array([1.        , 0.85714286]), array([0.88888889, 0.92307692]), array([ 8, 14]))\n",
      "accu:0.82\n",
      "prec:0.84\n",
      "rec:0.82\n",
      "f1:0.81\n",
      "{'clf__max_depth': 3, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "rmse test: 5.395851815404023\n",
      "rmse cv: -5.9329590583008045\n"
     ]
    }
   ],
   "source": [
    "# XGBoost - par speech only\n",
    "clf_xgb_par, rgs_xgb_par = baseline_models(train_df.joined_all_par_speech, train_df.ad, train_df.mmse, xgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 3, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 100, 'vec__stop_words': 'english', 'vec__sublinear_tf': False}\n",
      "prec, rec, f1 test (array([0.75, 0.8 ]), array([0.81818182, 0.72727273]), array([0.7826087 , 0.76190476]), array([11, 11]))\n",
      "accu:0.79\n",
      "prec:0.8\n",
      "rec:0.82\n",
      "f1:0.79\n",
      "{'clf__max_depth': 3, 'clf__n_estimators': 200, 'vec__analyzer': 'char', 'vec__max_features': 100, 'vec__stop_words': 'english', 'vec__sublinear_tf': False}\n",
      "rmse test: 6.370420306954228\n",
      "rmse cv: -5.603149994529027\n"
     ]
    }
   ],
   "source": [
    "# XGBoost - par + inv speech\n",
    "clf_xgb_all, rgs_xgb_all = baseline_models(train_df.joined_all_par_speech, train_df.ad, train_df.mmse, xgb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment Based Models\n",
    "- Treating each participant utterance as seperate data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode out each segment into AD / control segments\n",
    "# Do not shuffle, as parent level segments have already been shuffled\n",
    "segmented_speech = train_df.apply(lambda r: pd.DataFrame({'t_id': r.id, 'part_id': [str(i) for i, _ in enumerate(r.clean_par_speech)], 'speech_sent': r.clean_par_speech, 'ad': r.ad, 'mmse': r.mmse, 'age': r.age, 'sex': 1 if r.sex == 'm' else 0}), axis=1).tolist()\n",
    "train_df_segments = pd.concat(segmented_speech).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time features\n",
    "# - Embed time total time taken \n",
    "# - parse time blocks, take first and last\n",
    "# - Embed total time taken per sentence\n",
    "# - Time before starting speech\n",
    "# - Time in between each sentence\n",
    "# - Average / min / max / median time of sentence\n",
    "time_dims = train_df.loc[:, ['id', 'total_time', 'time_between_sents', 'per_sent_times']]\n",
    "time_dims['avg_sent_time'] = time_dims.per_sent_times.apply(lambda t: round(sum(t) / len(t)))\n",
    "time_dims['max_sent_time'] = time_dims.per_sent_times.apply(max)\n",
    "time_dims['min_sent_time'] = time_dims.per_sent_times.apply(min)\n",
    "time_dims_eng = time_dims.drop('time_between_sents', axis=1)\n",
    "\n",
    "def time_seg_df(r):\n",
    "    return pd.DataFrame({'t_id': r.id,\n",
    "                         'part_id': [str(i) for i, _ in enumerate(r.per_sent_times)],\n",
    "                         'total_time': r.total_time, \n",
    "                         'segment_time': [t for t in r.per_sent_times],\n",
    "                         'avg_sent_time': r.avg_sent_time,\n",
    "                         'max_sent_time': r.max_sent_time,\n",
    "                         'min_sent_time': r.min_sent_time,\n",
    "                         })\n",
    "time_dim_segments = pd.concat(time_dims_eng.apply(time_seg_df, axis=1).tolist())\n",
    "\n",
    "scaled = StandardScaler().fit_transform(time_dim_segments.loc[:, d_cols])\n",
    "\n",
    "d_cols = [c for c in time_dim_segments.columns if c not in ['t_id', 'part_id']]\n",
    "scaled = StandardScaler().fit_transform(time_dim_segments.loc[:, d_cols])\n",
    "for i, col in enumerate(d_cols):\n",
    "    time_dim_segments[col] = scaled[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_segments.age = StandardScaler().fit_transform(pd.DataFrame(train_df_segments.age.to_numpy()).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_segments = train_df_segments.merge(time_dim_segments, on=['t_id', 'part_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.0, 'clf__kernel': 'rbf', 'vec__analyzer': 'word', 'vec__max_features': 1000, 'vec__stop_words': None, 'vec__sublinear_tf': True}\n",
      "prec, rec, f1 test (array([0.93700787, 0.63905325]), array([0.66111111, 0.93103448]), array([0.7752443 , 0.75789474]), array([180, 116]))\n",
      "accu:0.72\n",
      "prec:0.73\n",
      "rec:0.72\n",
      "f1:0.72\n"
     ]
    }
   ],
   "source": [
    "# SVM - segmented\n",
    "clf_svm_segment, rgs_svm_segments = baseline_models(train_df_segments.speech_sent, train_df_segments.ad, train_df_segments.mmse, xgb=False, shuffle=False, print_stats=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': 3, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 1000, 'vec__stop_words': None, 'vec__sublinear_tf': False}\n",
      "prec, rec, f1 test (array([0.67625899, 0.68152866]), array([0.65277778, 0.70394737]), array([0.66431095, 0.69255663]), array([144, 152]))\n",
      "accu:0.68\n",
      "prec:0.67\n",
      "rec:0.72\n",
      "f1:0.69\n",
      "{'clf__max_depth': 3, 'clf__n_estimators': 100, 'vec__analyzer': 'word', 'vec__max_features': 500, 'vec__stop_words': None, 'vec__sublinear_tf': False}\n",
      "rmse test: 6.489430926085308\n",
      "rmse cv: -6.842354524498984\n"
     ]
    }
   ],
   "source": [
    "# XGBoost - segmented\n",
    "clf_xgb_segments, rgs_xgb_segments = baseline_models(train_df_segments.speech_sent, train_df_segments.ad, train_df_segments.mmse, xgb=True, shuffle=False, print_stats=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(df, base_clf_ft_probs, r, i):\n",
    "    # base clf \n",
    "    seq = df[base_clf_ft_probs].tolist()\n",
    "    seq_item = seq[i]\n",
    "    features = {\n",
    "        'bias': 1.,\n",
    "        'prob_ad': seq_item[1],\n",
    "        'prob_cc': seq_item[0],\n",
    "        # time based features\n",
    "        'total_time': r.total_time,\n",
    "        'segment_time': r.segment_time,\n",
    "        'avg_sent_time': r.avg_sent_time,\n",
    "        'max_sent_time': r.max_sent_time,\n",
    "        'min_sent_time': r.min_sent_time,\n",
    "        # demographics\n",
    "        'age': r.age,\n",
    "        'sex': r.sex,\n",
    "        # add in POS tags vectors?\n",
    "    }\n",
    "    # context features\n",
    "    if i > 0:\n",
    "        features.update({\n",
    "            '-1:prob_ad': seq[i-1][1],\n",
    "            '-1:prob_ad': seq[i-1][0],\n",
    "            '-1:segment_time': df.iloc[i-1].segment_time\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    \n",
    "    if i < len(seq) - 1:\n",
    "        features.update({\n",
    "            '+1:prob_ad': seq[i+1][1],\n",
    "            '+1:prob_cc': seq[i+1][0],\n",
    "            '+1:segment_time': df.iloc[i+1].segment_time\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_linear_CRF(base_clf_feature_name, segment_model):\n",
    "    accus, precs, recall, f1s = [], [], [], []\n",
    "    kf = KFold(n_splits=10, random_state=random_state, shuffle=False)\n",
    "    accus, precs, recall, f1s = [], [], [], []\n",
    "    for train_idxs, test_idxs in kf.split(train_df):\n",
    "        train_x_y =  train_df_segments[train_df_segments.t_id.isin(train_df.iloc[train_idxs].id)]\n",
    "        test_x_y = train_df_segments[train_df_segments.t_id.isin(train_df.iloc[test_idxs].id)]\n",
    "        train_x, train_y = train_x_y, train_x_y.ad.tolist()\n",
    "        test_x, test_y = test_x_y, test_x_y.ad.tolist()\n",
    "\n",
    "        # refit the base sentence 'embedding layer'. We've already found optimal hyper params - so no need to CV this model\n",
    "        segment_model.fit(train_x.speech_sent, train_y)\n",
    "        train_x[base_clf_feature_name] = segment_model.predict_proba(train_x.speech_sent).tolist()\n",
    "        test_x[base_clf_feature_name] = segment_model.predict_proba(test_x.speech_sent).tolist()\n",
    "\n",
    "        # Collapse sequences back into DataFrame with CRF features.\n",
    "        def crf_featurize(X, y):\n",
    "            collapsed_df = {'t_id': [], 'crf_features': [], 'ad': []}\n",
    "            for t_id, pt_sq in X.groupby('t_id', sort=False):\n",
    "                collapsed_df['t_id'].append(t_id)\n",
    "                collapsed_df['crf_features'].append([features(pt_sq, base_clf_feature_name, r, i) for i, r in enumerate(pt_sq.itertuples())])\n",
    "                collapsed_df['ad'].append([str(i) for i in pt_sq.ad])\n",
    "            collapsed_df = pd.DataFrame(collapsed_df)\n",
    "            return collapsed_df\n",
    "\n",
    "        seq_data_train = crf_featurize(train_x, train_y)\n",
    "        seq_data_test = crf_featurize(test_x, test_y)\n",
    "\n",
    "        params_space = {\n",
    "            'c1': scipy.stats.expon(scale=0.5).rvs(size=15),\n",
    "            'c2': scipy.stats.expon(scale=0.05).rvs(size=15),\n",
    "        }\n",
    "\n",
    "        crf = sklearn_crfsuite.CRF(\n",
    "            algorithm='lbfgs',\n",
    "            all_possible_transitions=True\n",
    "        )\n",
    "\n",
    "        gs = GridSearchCV(crf, params_space, cv=5, n_jobs=6)\n",
    "        gs.fit(seq_data_train.crf_features.tolist(), seq_data_train.ad)\n",
    "\n",
    "        # one last fit on all train_data\n",
    "        crf.set_params(**gs.best_params_)\n",
    "        crf.fit(seq_data_train.crf_features.tolist(), seq_data_train.ad)\n",
    "        last_test_labels = [p[-1] for p in seq_data_test.ad]\n",
    "        preds = [p[-1] for p in crf.predict(seq_data_test.crf_features)]\n",
    "        print(precision_recall_fscore_support(last_test_labels, preds, average='binary', pos_label='1'))\n",
    "        accus.append(accuracy_score(last_test_labels, preds))\n",
    "        p, r, f1, _ = precision_recall_fscore_support(last_test_labels, preds, average='binary', pos_label='1')\n",
    "        precs.append(p)\n",
    "        recall.append(r)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    return accus, precs, recall, f1s, crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.8333333333333334, 0.9090909090909091, None)\n",
      "(0.6666666666666666, 0.5714285714285714, 0.6153846153846153, None)\n",
      "(0.75, 0.75, 0.75, None)\n",
      "(0.8333333333333334, 1.0, 0.9090909090909091, None)\n",
      "(1.0, 1.0, 1.0, None)\n",
      "(1.0, 0.875, 0.9333333333333333, None)\n",
      "(1.0, 1.0, 1.0, None)\n",
      "(0.8, 1.0, 0.888888888888889, None)\n",
      "(1.0, 1.0, 1.0, None)\n",
      "(0.6, 0.75, 0.6666666666666665, None)\n"
     ]
    }
   ],
   "source": [
    "accus, precs, recallyry, f1s, svm_crf_model = cv_linear_CRF('clf_svm_preds', clf_svm_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg accu: 0.87\n",
      "avg precs: 0.86\n",
      "avg recall: 0.79\n",
      "avg f1s: 0.87\n"
     ]
    }
   ],
   "source": [
    "print('avg accu:', round(sum(accus) / len(accus), 2))\n",
    "print('avg precs:', round(sum(precs) / len(precs),2))\n",
    "print('avg recall:', round(sum(recall) / len(recall),2))\n",
    "print('avg f1s:', round(sum(f1s) / len(f1s),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.0036552258283559748, c2=0.018382304621495055,\n",
       "    calibration_candidates=None, calibration_eta=None,\n",
       "    calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=None,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)>"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_crf_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.8333333333333334, 0.9090909090909091, None)\n",
      "(0.8, 0.5714285714285714, 0.6666666666666666, None)\n",
      "(0.6666666666666666, 1.0, 0.8, None)\n",
      "(1.0, 1.0, 1.0, None)\n",
      "(0.8, 0.8, 0.8000000000000002, None)\n",
      "(1.0, 0.875, 0.9333333333333333, None)\n",
      "(1.0, 0.6, 0.7499999999999999, None)\n",
      "(0.75, 0.75, 0.75, None)\n",
      "(1.0, 1.0, 1.0, None)\n",
      "(0.6, 0.75, 0.6666666666666665, None)\n",
      "avg accu: 0.84\n",
      "avg precs: 0.86\n",
      "avg recall: 0.82\n",
      "avg f1s: 0.83\n",
      "CPU times: user 45min 10s, sys: 35.1 s, total: 45min 45s\n",
      "Wall time: 46min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accus, precs, recall, f1s, xgb_crf_model = cv_linear_CRF('clf_xgb_preds', clf_xgb_segments)\n",
    "print('avg accu:', round(sum(accus) / len(accus), 2))\n",
    "print('avg precs:', round(sum(precs) / len(precs),2))\n",
    "print('avg recall:', round(sum(recall) / len(recall),2))\n",
    "print('avg f1s:', round(sum(f1s) / len(f1s),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.3140761504844387, c2=0.00890634380131646,\n",
       "    calibration_candidates=None, calibration_eta=None,\n",
       "    calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=None,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)>"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_crf_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg accu: 0.8\n",
      "avg precs: 0.84\n",
      "avg recall: 0.74\n",
      "avg f1s: 0.78\n"
     ]
    }
   ],
   "source": [
    "print('avg accu:', round(sum(accus) / len(accus), 2))\n",
    "print('avg precs:', round(sum(precs) / len(precs),2))\n",
    "print('avg recall:', round(sum(recall) / len(recall),2))\n",
    "print('avg f1s:', round(sum(f1s) / len(f1s),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg accu: 0.82\n",
      "avg precs: 0.84\n",
      "avg recall: 0.79\n",
      "avg f1s: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('avg accu:', round(sum(accus) / len(accus), 2))\n",
    "print('avg precs:', round(sum(precs) / len(precs),2))\n",
    "print('avg recall:', round(sum(recall) / len(recall),2))\n",
    "print('avg f1s:', round(sum(f1s) / len(f1s),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_impor(pipe):\n",
    "    feat_impor = [(pipe.steps[0][1].get_feature_names()[i], pipe.steps[1][1].feature_importances_[i]) for i in np.argsort(pipe.steps[1][1].feature_importances_)[::-1][0:20]]\n",
    "    labs = [i[0] for i in feat_impor]\n",
    "    scores = [i[1] for i in feat_impor]\n",
    "    return labs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_feats(clf_labels, clf_impor, rgs_labels, rgs_impor):\n",
    "    fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(8, 5))\n",
    "    ax1.barh(range(len(clf_impor)), clf_impor, label='AD Classification')\n",
    "    ax1.set_yticks(range(len(clf_labels)))\n",
    "    ax1.set_ylabel('TF-IDF Feature')\n",
    "    ax1.set_yticklabels(clf_labels)\n",
    "    ax1.yaxis.set_tick_params(labelsize=14)\n",
    "    ax1.set_xlabel('Feature Importance')\n",
    "\n",
    "    ax2.barh(range(len(rgs_labels)), rgs_impor, label='MMSE Regression')\n",
    "    ax2.set_yticks(range(len(rgs_labels)))\n",
    "    ax2.yaxis.set_tick_params(labelsize=14)\n",
    "    ax2.set_yticklabels(rgs_labels)\n",
    "    ax2.set_xlabel('Feature Importance')\n",
    "\n",
    "    # plt.legend([bar1, bar2], [bar1.get_label(), bar2.get_label()], fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./feat_impor_xgboost.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clf_labels, clf_impor = \n",
    "# rgs_labels, rgs_impor =\n",
    "plt_feats(*feat_impor(clf_xgb_par), * feat_impor(rgs_xgb_par))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (type) model Experimentaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding function\n",
    "def bert_embed(text: pd.Series, tokenizer, model):\n",
    "    tokenized = text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512)))\n",
    "\n",
    "    # pad so can be treated as one batch\n",
    "    max_len = max([len(i) for i in tokenized.values])\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "    # attention mask - zero out attention scores where there is no input to be processed (i.e. is padding)\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    input_ids = torch.tensor(padded)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # check if multiple GPUs are available\n",
    "    multi_gpu = torch.cuda.device_count() > 1\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    last_hidden_states = last_hidden_states[0]\n",
    "    if device.type == 'cuda':\n",
    "        last_hidden_states = last_hidden_states.cpu()\n",
    "    features = last_hidden_states[:,0,:].numpy()\n",
    "    return features, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear classifier fit/transform\n",
    "def fit_transform(features, labels: list, mmse: list):\n",
    "    def cv10_avg_nn(score):\n",
    "        return cv10_avg(score, lr_clf, features, labels)\n",
    "\n",
    "    # AD classification task\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=random_state)\n",
    "    parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "    grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
    "    grid_search.fit(train_features, train_labels)\n",
    "    print('best parameters:', grid_search.best_params_)\n",
    "    print('best scores: ', grid_search.best_score_)\n",
    "    lr_clf = LogisticRegression(**grid_search.best_params_)\n",
    "    lr_clf.fit(train_features, train_labels)\n",
    "    preds = lr_clf.predict(test_features)\n",
    "    print('prec, rec, f1 test', precision_recall_fscore_support(test_labels, preds))\n",
    "    print(f'accu:{cv10_avg_nn(\"accuracy\")} prec:{cv10_avg_nn(\"precision\")}, rec:{cv10_avg_nn(\"recall\")}, f1:{cv10_avg_nn(\"f1\")}')\n",
    "          \n",
    "    # MMSE regression task\n",
    "    # remove missing row\n",
    "    reg_features, reg_scores = pd.DataFrame(features).drop([i for i, s in enumerate(mmse) if s == '']).to_numpy(), [s for s in mmse if s != '']\n",
    "    train_features, test_features, train_scores, test_scores = train_test_split(reg_features, reg_scores, random_state=random_state)\n",
    "    parameters = {'alpha': np.linspace(0.001, 100, 20)}\n",
    "    grid_search = GridSearchCV(Ridge(), parameters)\n",
    "    grid_search.fit(train_features, train_scores)\n",
    "    print('best parameters:', grid_search.best_params_)\n",
    "    print('best scores: ', grid_search.best_score_)\n",
    "    reg_model = Ridge(**grid_search.best_params_)\n",
    "    reg_model.fit(train_features, train_scores)\n",
    "    preds = reg_model.predict(test_features)\n",
    "    print('rmse test:', sqrt(mean_squared_error(test_scores, preds)))\n",
    "    print('rmse cv:', cross_val_score(reg_model, reg_features, reg_scores, cv=10, scoring='neg_root_mean_squared_error').sum() / 10)\n",
    "    return lr_clf, reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Large\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-large-uncased')\n",
    "\n",
    "# roBERTa base\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transformer_model_tokenizer(model_class, tokenizer_class, pretrained_weights):\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_class, tokenizer_class, pretrained_weights, text):\n",
    "    tokenizer, model = load_transformer_model_tokenizer(model_class, tokenizer_class, pretrained_weights)\n",
    "    features, _ = bert_embed(text, tokenizer, model)\n",
    "    clf_model, reg_model = fit_transform(features, train_df.ad, train_df.mmse)\n",
    "    return tokenizer, model, features, clf_model, reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8279411764705882\n",
      "prec, rec, f1 test (array([0.81818182, 0.8125    ]), array([0.75      , 0.86666667]), array([0.7826087 , 0.83870968]), array([12, 15]))\n",
      "accu:0.87 prec:0.9, rec:0.87, f1:0.87\n",
      "best parameters: {'alpha': 5.264105263157894}\n",
      "best scores:  0.48426174008121115\n",
      "rmse test: 5.156365006865598\n",
      "rmse cv: -4.496598650519269\n"
     ]
    }
   ],
   "source": [
    "# Distil BERT - par speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_par_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8294117647058823\n",
      "prec, rec, f1 test (array([1.        , 0.88235294]), array([0.83333333, 1.        ]), array([0.90909091, 0.9375    ]), array([12, 15]))\n",
      "accu:0.84 prec:0.86, rec:0.85, f1:0.82\n",
      "best parameters: {'alpha': 0.001}\n",
      "best scores:  0.39129614202351315\n",
      "rmse test: 5.99993232969807\n",
      "rmse cv: -5.125356983051849\n"
     ]
    }
   ],
   "source": [
    "# Distil roBERTa\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'distilroberta-base')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_par_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8294117647058823\n",
      "prec, rec, f1 test (array([1.        , 0.88235294]), array([0.83333333, 1.        ]), array([0.90909091, 0.9375    ]), array([12, 15]))\n",
      "accu:0.84 prec:0.86, rec:0.85, f1:0.82\n",
      "best parameters: {'alpha': 0.001}\n",
      "best scores:  0.39129614202351315\n",
      "rmse test: 5.99993232969807\n",
      "rmse cv: -5.125356983051849\n"
     ]
    }
   ],
   "source": [
    "# BERT Base\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_par_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8147058823529412\n",
      "prec, rec, f1 test (array([0.90909091, 0.875     ]), array([0.83333333, 0.93333333]), array([0.86956522, 0.90322581]), array([12, 15]))\n",
      "accu:0.87 prec:0.89, rec:0.89, f1:0.88\n",
      "best parameters: {'alpha': 5.264105263157894}\n",
      "best scores:  0.4361080418716384\n",
      "rmse test: 5.891775312607294\n",
      "rmse cv: -4.8560381474639875\n"
     ]
    }
   ],
   "source": [
    "# Distil BERT - par + inv speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10.526405263157894}\n",
      "best scores:  0.8169117647058822\n",
      "prec, rec, f1 test (array([1.    , 0.9375]), array([0.91666667, 1.        ]), array([0.95652174, 0.96774194]), array([12, 15]))\n",
      "accu:0.8 prec:0.87, rec:0.79, f1:0.78\n",
      "best parameters: {'alpha': 0.001}\n",
      "best scores:  0.43956916829704706\n",
      "rmse test: 5.961039275583074\n",
      "rmse cv: -4.485702271630474\n"
     ]
    }
   ],
   "source": [
    "# Distil roBERT - par + inv speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'distilroberta-base')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ca069d2bf74fa485aa50e63c74c4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.7661764705882353\n",
      "prec, rec, f1 test (array([0.90909091, 0.875     ]), array([0.83333333, 0.93333333]), array([0.86956522, 0.90322581]), array([12, 15]))\n",
      "accu:0.75 prec:0.76, rec:0.78, f1:0.74\n",
      "best parameters: {'alpha': 5.264105263157894}\n",
      "best scores:  0.4176459962509897\n",
      "rmse test: 6.609310719210884\n",
      "rmse cv: -5.273888313820208\n"
     ]
    }
   ],
   "source": [
    "# BERT Base -  par + inv speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f5cc4b4ada401da60190ee1381c963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best parameters: {'C': 15.789557894736841}\n",
      "best scores:  0.7411764705882353\n",
      "prec, rec, f1 test (array([0.76923077, 0.85714286]), array([0.83333333, 0.8       ]), array([0.8       , 0.82758621]), array([12, 15]))\n",
      "accu:0.72 prec:0.71, rec:0.71, f1:0.69\n",
      "best parameters: {'alpha': 0.001}\n",
      "best scores:  0.2898992821805212\n",
      "rmse test: 5.4664368013907065\n",
      "rmse cv: -5.453310614652553\n"
     ]
    }
   ],
   "source": [
    "# roBERTa Base - par + inv speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb29f238c1944a058d16fc93cff09407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3658efce3b1a46d5ab893e31023e4a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db98b171999249a782700872eddb0a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63ed71337064d6fb15c3c5ed7362ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best parameters: {'C': 5.263252631578947}\n",
      "best scores:  0.8154411764705882\n",
      "prec, rec, f1 test (array([0.84615385, 0.92857143]), array([0.91666667, 0.86666667]), array([0.88      , 0.89655172]), array([12, 15]))\n",
      "accu:0.81 prec:0.88, rec:0.76, f1:0.79\n",
      "best parameters: {'alpha': 0.001}\n",
      "best scores:  0.39037099767627437\n",
      "rmse test: 5.765437868458934\n",
      "rmse cv: -5.818066430419618\n"
     ]
    }
   ],
   "source": [
    "# roBERTa Large - par + inv speech\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-large')\n",
    "tokenizer, model, features, clf_model, reg_model = run_model(model_class, tokenizer_class, pretrained_weights, train_df.joined_all_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_transformer_model_tokenizer(ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "sent_features, mask = bert_embed(train_df_segments.speech_sent, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_segments['features'] = [sent for sent in sent_features]\n",
    "train_df_segments['mask'] = [m for m in mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sent_features_ad_chalng_distil_bert.npy', sent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sent_mask_ad_chalng_distil_bert.npy', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 6)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>speech_sent</th>\n",
       "      <th>ad</th>\n",
       "      <th>mmse</th>\n",
       "      <th>features</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S072</td>\n",
       "      <td>you mean right now tell you ?</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.063634075, -0.02579525, -0.11341515, -0.195...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S072</td>\n",
       "      <td>&amp;uh the boy is stealing cookies out_of the jar .</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.1428656, 0.107771605, 0.17008701, -0.13180...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S072</td>\n",
       "      <td>and he's on a stool that's falling down .</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.115731, -0.06755233, 0.051717915, -0.20882...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S072</td>\n",
       "      <td>and the girl is laughing at him .</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.106318496, -0.04198377, 0.11833834, -0.152...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S072</td>\n",
       "      <td>and the mother is washing dishes but she's pre...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.014219768, -0.102059945, 0.15856433, -0.20...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>S083</td>\n",
       "      <td>telling him to be quiet .</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>[-0.20028175, -0.17130803, -0.19182582, -0.256...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>S083</td>\n",
       "      <td>and &amp;uh let's see .</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.022183776, 0.0958084, 0.25372738, -0.208391...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>S083</td>\n",
       "      <td>in the meantime &amp;uh the mother is washing the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>[-0.05771879, -0.07798436, 0.24423543, -0.1021...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>S083</td>\n",
       "      <td>(..) I don't think I see anything else .</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.08366716, 0.04091748, -0.0035671964, -0.260...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>S083</td>\n",
       "      <td>okay .</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.027815111, -0.15054692, 0.16559032, -0.1801...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1476 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        speech_sent  ad mmse  \\\n",
       "0     S072                      you mean right now tell you ?   0   29   \n",
       "1     S072   &uh the boy is stealing cookies out_of the jar .   0   29   \n",
       "2     S072          and he's on a stool that's falling down .   0   29   \n",
       "3     S072                  and the girl is laughing at him .   0   29   \n",
       "4     S072  and the mother is washing dishes but she's pre...   0   29   \n",
       "...    ...                                                ...  ..  ...   \n",
       "1471  S083                          telling him to be quiet .   1   30   \n",
       "1472  S083                                and &uh let's see .   1   30   \n",
       "1473  S083  in the meantime &uh the mother is washing the ...   1   30   \n",
       "1474  S083           (..) I don't think I see anything else .   1   30   \n",
       "1475  S083                                             okay .   1   30   \n",
       "\n",
       "                                               features  \\\n",
       "0     [0.063634075, -0.02579525, -0.11341515, -0.195...   \n",
       "1     [-0.1428656, 0.107771605, 0.17008701, -0.13180...   \n",
       "2     [-0.115731, -0.06755233, 0.051717915, -0.20882...   \n",
       "3     [-0.106318496, -0.04198377, 0.11833834, -0.152...   \n",
       "4     [-0.014219768, -0.102059945, 0.15856433, -0.20...   \n",
       "...                                                 ...   \n",
       "1471  [-0.20028175, -0.17130803, -0.19182582, -0.256...   \n",
       "1472  [0.022183776, 0.0958084, 0.25372738, -0.208391...   \n",
       "1473  [-0.05771879, -0.07798436, 0.24423543, -0.1021...   \n",
       "1474  [0.08366716, 0.04091748, -0.0035671964, -0.260...   \n",
       "1475  [0.027815111, -0.15054692, 0.16559032, -0.1801...   \n",
       "\n",
       "                                                   mask  \n",
       "0     [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1     [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "2     [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "3     [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "4     [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "...                                                 ...  \n",
       "1471  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1472  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1473  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1474  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1475  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "\n",
       "[1476 rows x 6 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and that's all I see on that .\n",
      "okay, I see a boy in the cookie jar .\n",
      "I see he has the lid off .\n",
      "I see that he is standing on a three legged stool and he's about todepart from that three legged stool .\n",
      "he has one cookie in his hand, handin(g) it down to his sister andshe's reaching up for it .\n",
      "and I think she's indicating to the boy to keep still so his motherdoesn't hear what's going on .\n",
      "I see the mother .\n",
      "&uh I guess she's drying the dishes and she's not paying attentionbecause she's &uh leavin(g) the sink run over and it's spillin(g)all over the floor .\n",
      "and she must not be conscious because she's standing in it anddoesn't know it .\n",
      "&um &sh I think she must  I think she's probably lookin(g)out the window as I take the second look .\n",
      "and I see apparently a couple dirty dishes on the table+top .\n",
      "I see the cupboards .\n",
      "&uh I don't know whether they all have knobs on them or not .\n",
      "doesn't look like the two where the boy and the girl are have knobson the cupboard door .\n",
      "and I see outside .\n",
      "I see &uh apparently it's a tree, some shrubbery and some hedges .\n",
      "about it ?\n",
      "(.) I don't see xxx .\n",
      "(loo)ks like somebody took some pencils or somethin(g) and went upand down those xxx them things .\n",
      "all I see  I see a girl standin(g) there or somethin(g) orother .\n",
      "(.) some little knots\n",
      "I don't know .\n",
      "(.) some kind of a xxx pan or somethin(g) .\n",
      "(.) and that girl is there .\n",
      "(.) and there's somethin(g) else over there .\n",
      "(.) there's another girl (.) look like .\n",
      "looks +/.\n",
      "look like some\n",
      "I don't see nothin(g) else .\n",
      "some of xxx and things .\n",
      "look to me like the same except them things up there .\n",
      "(..) I see this they all look  looked about the same to meexcept this thing here .\n",
      "look like a little kid the same .\n",
      "(.) I'm sorry I didn't bring my glasses .\n",
      "well the kid's standin(g) on a tilted stool gettin(g) cookies .\n",
      "the water's runnin(g) out o(f) the sink .\n",
      "the girl has two different shoes on .\n",
      "the stool is tilted .\n",
      "(..) the cookie jar is not a jar it's  it's a &uhtin  tin dish or whatever .\n",
      "okay he's fallin(g) off a chair  .\n",
      "she's &uh running the water over .\n",
      "can't see anything else .\n",
      "no .\n",
      "+ okay .\n",
      "she's\n",
      "no .\n",
      "oh sure .\n",
      "the little girl's standing in the kitchen .\n",
      "and then the little boy steps on a  to get some cookies .\n",
      "and he's about to fall down .\n",
      "and his mother isn't aware of it yet .\n",
      "she's still washing dishes .\n",
      "and then the sink ran over I guess when she got excited .\n",
      "and it's going down on a  on the &s floor in the kitchen .\n",
      "and she's trying to dry the dishes .\n",
      "and she's just standing there .\n",
      "she still has dishes to go I guess .\n",
      "and this little boy is about to fall .\n",
      "and this little girl is smiling at him because he's going for thecookies in the cookie jar &=laughs .\n",
      "you want me to tell you ?\n",
      "okay &uh the boy's getting in the cookie jar .\n",
      "his sister's waiting for cookies .\n",
      "the mother's washing dishes and water's spilling over .\n",
      "&uh can see the walk and the grass outside in the window .\n",
      "the &uh stool's about ready to fall .\n",
      "the cupboard door's open .\n",
      "touching lip .\n",
      "raising arm .\n",
      "is that what you mean ?\n",
      "+ &lea reaching for cookie .\n",
      "handing cookie down .\n",
      "slipping from stool .\n",
      "stool falling over .\n",
      "&um wiping dishes .\n",
      "water running .\n",
      "water overflowing .\n",
      "&um breeze .\n",
      "I don't know if that's action .\n",
      "&um stepping out from water .\n",
      "I guess that's it .\n",
      "well  the boy's trying to get in this cookie jar .\n",
      "and the stool overturns .\n",
      "and &uh the little girl is expecting to hand her a cookie .\n",
      "&uh the mother is  her sink is running over .\n",
      "and she's standing in some of the water .\n",
      "and &uh she's drying a dish or wiping a dish .\n",
      "and &uh (.) you said everything is happening .\n",
      "(..) well  the water is still runnin(g) in the sink .\n",
      "and I said it's  it's overflowing .\n",
      "and she's standing in the water .\n",
      "and that's +...\n",
      "I guess .\n",
      "look  somebody laying in the lawn out there .\n",
      "but I can't &uh &=laughs +...\n",
      "mhm .\n",
      "there's a young boy &uh going in a cookie jar .\n",
      "and there's a  young girl .\n",
      "and I'm sayin(g) he's a boy (be)cause you can  &hard it'shardly  hard to tell anymore .\n",
      "&uh and he's  he's in the &c &t cookie jar .\n",
      "and there's a &s stool that he is on and it already is starting tofall over .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(l) for l in train_df_segments.speech_sent[100:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AD_LSTM(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim: int, layers=2, hidden_dim=300, dropout=.5, layers=1):\n",
    "        self.rnn = torch.nn.LSTM(input_dim, hidden_dim, layers)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.fc1 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # ignore padding\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x, mask.sum(1).int().view(-1), batch_first=True, enforce_sorted=False)\n",
    "        x, hidden = self.rnn(x)\n",
    "        x, _ = torch.nn.utils.pad_packed_sequence(x, batch_first=True)\n",
    "        rows = torch.arange(0, x.size(0).long())\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForADClassification(torch.nn.Module):\n",
    "    def __init__(self, bertModel, time_dims,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bertModel = bertModel\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        \n",
    "        # separate Linear for OHE of time\n",
    "        bert_hidden_dim = self.bertModel\n",
    "    \n",
    "        self.classifier = nn.Linear()\n",
    "    \n",
    "    def forward(input_ids, attention_mask):\n",
    "        last_hidden_states = self.bertModel(input_ids, attention_mask=attention_mask)\n",
    "        features = last_hidden_states[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all features\n",
    "features = np.hstack([bert_features, time_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:distil_bert]",
   "language": "python",
   "name": "conda-env-distil_bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
